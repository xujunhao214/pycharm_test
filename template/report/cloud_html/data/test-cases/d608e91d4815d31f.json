{
  "uid" : "d608e91d4815d31f",
  "name" : "多账号批量解绑：取消订阅 + 前端解绑 + 数据库校验",
  "fullName" : "test_cloudTrader.test_add_delete.Test_delete_batch#test_batch_unbind",
  "historyId" : "d80d276bbf6d19c21a2d7d69111a0c08",
  "time" : {
    "start" : 1760605837540,
    "stop" : 1760605837591,
    "duration" : 51
  },
  "description" : "当前解绑账号：301392107（pass_id：1978749475881971714）",
  "descriptionHtml" : "<p>当前解绑账号：301392107（pass_id：1978749475881971714）</p>\n",
  "status" : "failed",
  "statusMessage" : "Failed: 账号[301392107]解绑失败：Failed: DELETE请求网络层异常（HTTPSConnectionPool(host='dev.lgcopytrade.top', port=443): Max retries exceeded with url: /api/blockchain/master-slave/deletePa?id=1978749551737966594 (Caused by ProxyError('Unable to connect to proxy', FileNotFoundError(2, 'No such file or directory')))）",
  "statusTrace" : "self = <urllib3.connectionpool.HTTPSConnectionPool object at 0x000001D22C9D3850>\nmethod = 'DELETE'\nurl = '/api/blockchain/master-slave/deletePa?id=1978749551737966594'\nbody = b'null'\nheaders = {'User-Agent': 'python-requests/2.32.4', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-aliv...nant_id': '0', 'Content-Type': 'application/json; charset=utf-8', 'Host': 'dev.lgcopytrade.top', 'Content-Length': '4'}\nretries = Retry(total=0, connect=None, read=False, redirect=None, status=None)\nredirect = False, assert_same_host = False\ntimeout = Timeout(connect=None, read=None, total=None), pool_timeout = None\nrelease_conn = False, chunked = False, body_pos = None, preload_content = False\ndecode_content = False, response_kw = {}\nparsed_url = Url(scheme=None, auth=None, host=None, port=None, path='/api/blockchain/master-slave/deletePa', query='id=1978749551737966594', fragment=None)\ndestination_scheme = None, conn = None, release_this_conn = True\nhttp_tunnel_required = True, err = None, clean_exit = False\n\n    def urlopen(  # type: ignore[override]\n        self,\n        method: str,\n        url: str,\n        body: _TYPE_BODY | None = None,\n        headers: typing.Mapping[str, str] | None = None,\n        retries: Retry | bool | int | None = None,\n        redirect: bool = True,\n        assert_same_host: bool = True,\n        timeout: _TYPE_TIMEOUT = _DEFAULT_TIMEOUT,\n        pool_timeout: int | None = None,\n        release_conn: bool | None = None,\n        chunked: bool = False,\n        body_pos: _TYPE_BODY_POSITION | None = None,\n        preload_content: bool = True,\n        decode_content: bool = True,\n        **response_kw: typing.Any,\n    ) -> BaseHTTPResponse:\n        \"\"\"\n        Get a connection from the pool and perform an HTTP request. This is the\n        lowest level call for making a request, so you'll need to specify all\n        the raw details.\n    \n        .. note::\n    \n           More commonly, it's appropriate to use a convenience method\n           such as :meth:`request`.\n    \n        .. note::\n    \n           `release_conn` will only behave as expected if\n           `preload_content=False` because we want to make\n           `preload_content=False` the default behaviour someday soon without\n           breaking backwards compatibility.\n    \n        :param method:\n            HTTP request method (such as GET, POST, PUT, etc.)\n    \n        :param url:\n            The URL to perform the request on.\n    \n        :param body:\n            Data to send in the request body, either :class:`str`, :class:`bytes`,\n            an iterable of :class:`str`/:class:`bytes`, or a file-like object.\n    \n        :param headers:\n            Dictionary of custom headers to send, such as User-Agent,\n            If-None-Match, etc. If None, pool headers are used. If provided,\n            these headers completely replace any pool-specific headers.\n    \n        :param retries:\n            Configure the number of retries to allow before raising a\n            :class:`~urllib3.exceptions.MaxRetryError` exception.\n    \n            If ``None`` (default) will retry 3 times, see ``Retry.DEFAULT``. Pass a\n            :class:`~urllib3.util.retry.Retry` object for fine-grained control\n            over different types of retries.\n            Pass an integer number to retry connection errors that many times,\n            but no other types of errors. Pass zero to never retry.\n    \n            If ``False``, then retries are disabled and any exception is raised\n            immediately. Also, instead of raising a MaxRetryError on redirects,\n            the redirect response will be returned.\n    \n        :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.\n    \n        :param redirect:\n            If True, automatically handle redirects (status codes 301, 302,\n            303, 307, 308). Each redirect counts as a retry. Disabling retries\n            will disable redirect, too.\n    \n        :param assert_same_host:\n            If ``True``, will make sure that the host of the pool requests is\n            consistent else will raise HostChangedError. When ``False``, you can\n            use the pool on an HTTP proxy and request foreign hosts.\n    \n        :param timeout:\n            If specified, overrides the default timeout for this one\n            request. It may be a float (in seconds) or an instance of\n            :class:`urllib3.util.Timeout`.\n    \n        :param pool_timeout:\n            If set and the pool is set to block=True, then this method will\n            block for ``pool_timeout`` seconds and raise EmptyPoolError if no\n            connection is available within the time period.\n    \n        :param bool preload_content:\n            If True, the response's body will be preloaded into memory.\n    \n        :param bool decode_content:\n            If True, will attempt to decode the body based on the\n            'content-encoding' header.\n    \n        :param release_conn:\n            If False, then the urlopen call will not release the connection\n            back into the pool once a response is received (but will release if\n            you read the entire contents of the response such as when\n            `preload_content=True`). This is useful if you're not preloading\n            the response's content immediately. You will need to call\n            ``r.release_conn()`` on the response ``r`` to return the connection\n            back into the pool. If None, it takes the value of ``preload_content``\n            which defaults to ``True``.\n    \n        :param bool chunked:\n            If True, urllib3 will send the body using chunked transfer\n            encoding. Otherwise, urllib3 will send the body using the standard\n            content-length form. Defaults to False.\n    \n        :param int body_pos:\n            Position to seek to in file-like body in the event of a retry or\n            redirect. Typically this won't need to be set because urllib3 will\n            auto-populate the value when needed.\n        \"\"\"\n        parsed_url = parse_url(url)\n        destination_scheme = parsed_url.scheme\n    \n        if headers is None:\n            headers = self.headers\n    \n        if not isinstance(retries, Retry):\n            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)\n    \n        if release_conn is None:\n            release_conn = preload_content\n    \n        # Check host\n        if assert_same_host and not self.is_same_host(url):\n            raise HostChangedError(self, url, retries)\n    \n        # Ensure that the URL we're connecting to is properly encoded\n        if url.startswith(\"/\"):\n            url = to_str(_encode_target(url))\n        else:\n            url = to_str(parsed_url.url)\n    \n        conn = None\n    \n        # Track whether `conn` needs to be released before\n        # returning/raising/recursing. Update this variable if necessary, and\n        # leave `release_conn` constant throughout the function. That way, if\n        # the function recurses, the original value of `release_conn` will be\n        # passed down into the recursive call, and its value will be respected.\n        #\n        # See issue #651 [1] for details.\n        #\n        # [1] <https://github.com/urllib3/urllib3/issues/651>\n        release_this_conn = release_conn\n    \n        http_tunnel_required = connection_requires_http_tunnel(\n            self.proxy, self.proxy_config, destination_scheme\n        )\n    \n        # Merge the proxy headers. Only done when not using HTTP CONNECT. We\n        # have to copy the headers dict so we can safely change it without those\n        # changes being reflected in anyone else's copy.\n        if not http_tunnel_required:\n            headers = headers.copy()  # type: ignore[attr-defined]\n            headers.update(self.proxy_headers)  # type: ignore[union-attr]\n    \n        # Must keep the exception bound to a separate variable or else Python 3\n        # complains about UnboundLocalError.\n        err = None\n    \n        # Keep track of whether we cleanly exited the except block. This\n        # ensures we do proper cleanup in finally.\n        clean_exit = False\n    \n        # Rewind body position, if needed. Record current position\n        # for future rewinds in the event of a redirect/retry.\n        body_pos = set_file_position(body, body_pos)\n    \n        try:\n            # Request a connection from the queue.\n            timeout_obj = self._get_timeout(timeout)\n            conn = self._get_conn(timeout=pool_timeout)\n    \n            conn.timeout = timeout_obj.connect_timeout  # type: ignore[assignment]\n    \n            # Is this a closed/new connection that requires CONNECT tunnelling?\n            if self.proxy is not None and http_tunnel_required and conn.is_closed:\n                try:\n>                   self._prepare_proxy(conn)\n\n..\\Community\\lib\\site-packages\\urllib3\\connectionpool.py:775: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n..\\Community\\lib\\site-packages\\urllib3\\connectionpool.py:1044: in _prepare_proxy\n    conn.connect()\n..\\Community\\lib\\site-packages\\urllib3\\connection.py:702: in connect\n    self.sock = sock = self._connect_tls_proxy(self.host, sock)\n..\\Community\\lib\\site-packages\\urllib3\\connection.py:802: in _connect_tls_proxy\n    sock_and_verified = _ssl_wrap_socket_and_match_hostname(\n..\\Community\\lib\\site-packages\\urllib3\\connection.py:909: in _ssl_wrap_socket_and_match_hostname\n    ssl_sock = ssl_wrap_socket(\n..\\Community\\lib\\site-packages\\urllib3\\util\\ssl_.py:469: in ssl_wrap_socket\n    ssl_sock = _ssl_wrap_socket_impl(sock, context, tls_in_tls, server_hostname)\n..\\Community\\lib\\site-packages\\urllib3\\util\\ssl_.py:513: in _ssl_wrap_socket_impl\n    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)\nD:\\python_tools\\python\\lib\\ssl.py:500: in wrap_socket\n    return self.sslsocket_class._create(\nD:\\python_tools\\python\\lib\\ssl.py:1040: in _create\n    self.do_handshake()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <ssl.SSLSocket [closed] fd=-1, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0>\nblock = False\n\n    @_sslcopydoc\n    def do_handshake(self, block=False):\n        self._check_connected()\n        timeout = self.gettimeout()\n        try:\n            if timeout == 0.0 and block:\n                self.settimeout(None)\n>           self._sslobj.do_handshake()\nE           FileNotFoundError: [Errno 2] No such file or directory\n\nD:\\python_tools\\python\\lib\\ssl.py:1309: FileNotFoundError\n\nThe above exception was the direct cause of the following exception:\nTraceback (most recent call last):\n  File \"D:\\pycharm_test\\Community\\lib\\site-packages\\urllib3\\connectionpool.py\", line 775, in urlopen\n    self._prepare_proxy(conn)\n  File \"D:\\pycharm_test\\Community\\lib\\site-packages\\urllib3\\connectionpool.py\", line 1044, in _prepare_proxy\n    conn.connect()\n  File \"D:\\pycharm_test\\Community\\lib\\site-packages\\urllib3\\connection.py\", line 702, in connect\n    self.sock = sock = self._connect_tls_proxy(self.host, sock)\n  File \"D:\\pycharm_test\\Community\\lib\\site-packages\\urllib3\\connection.py\", line 802, in _connect_tls_proxy\n    sock_and_verified = _ssl_wrap_socket_and_match_hostname(\n  File \"D:\\pycharm_test\\Community\\lib\\site-packages\\urllib3\\connection.py\", line 909, in _ssl_wrap_socket_and_match_hostname\n    ssl_sock = ssl_wrap_socket(\n  File \"D:\\pycharm_test\\Community\\lib\\site-packages\\urllib3\\util\\ssl_.py\", line 469, in ssl_wrap_socket\n    ssl_sock = _ssl_wrap_socket_impl(sock, context, tls_in_tls, server_hostname)\n  File \"D:\\pycharm_test\\Community\\lib\\site-packages\\urllib3\\util\\ssl_.py\", line 513, in _ssl_wrap_socket_impl\n    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)\n  File \"D:\\python_tools\\python\\lib\\ssl.py\", line 500, in wrap_socket\n    return self.sslsocket_class._create(\n  File \"D:\\python_tools\\python\\lib\\ssl.py\", line 1040, in _create\n    self.do_handshake()\n  File \"D:\\python_tools\\python\\lib\\ssl.py\", line 1309, in do_handshake\n    self._sslobj.do_handshake()\nFileNotFoundError: [Errno 2] No such file or directory\n\nThe above exception was the direct cause of the following exception:\n\nurllib3.exceptions.ProxyError: ('Unable to connect to proxy', FileNotFoundError(2, 'No such file or directory'))\n\nThe above exception was the direct cause of the following exception:\n\nself = <requests.adapters.HTTPAdapter object at 0x000001D22C6C4E80>\nrequest = <PreparedRequest [DELETE]>, stream = False\ntimeout = Timeout(connect=None, read=None, total=None), verify = True\ncert = None\nproxies = OrderedDict([('http', 'http://127.0.0.1:10809'), ('https', 'https://127.0.0.1:10809'), ('ftp', 'ftp://127.0.0.1:10809')])\n\n    def send(\n        self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None\n    ):\n        \"\"\"Sends PreparedRequest object. Returns Response object.\n    \n        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\n        :param stream: (optional) Whether to stream the request content.\n        :param timeout: (optional) How long to wait for the server to send\n            data before giving up, as a float, or a :ref:`(connect timeout,\n            read timeout) <timeouts>` tuple.\n        :type timeout: float or tuple or urllib3 Timeout object\n        :param verify: (optional) Either a boolean, in which case it controls whether\n            we verify the server's TLS certificate, or a string, in which case it\n            must be a path to a CA bundle to use\n        :param cert: (optional) Any user-provided SSL certificate to be trusted.\n        :param proxies: (optional) The proxies dictionary to apply to the request.\n        :rtype: requests.Response\n        \"\"\"\n    \n        try:\n            conn = self.get_connection_with_tls_context(\n                request, verify, proxies=proxies, cert=cert\n            )\n        except LocationValueError as e:\n            raise InvalidURL(e, request=request)\n    \n        self.cert_verify(conn, request.url, verify, cert)\n        url = self.request_url(request, proxies)\n        self.add_headers(\n            request,\n            stream=stream,\n            timeout=timeout,\n            verify=verify,\n            cert=cert,\n            proxies=proxies,\n        )\n    \n        chunked = not (request.body is None or \"Content-Length\" in request.headers)\n    \n        if isinstance(timeout, tuple):\n            try:\n                connect, read = timeout\n                timeout = TimeoutSauce(connect=connect, read=read)\n            except ValueError:\n                raise ValueError(\n                    f\"Invalid timeout {timeout}. Pass a (connect, read) timeout tuple, \"\n                    f\"or a single float to set both timeouts to the same value.\"\n                )\n        elif isinstance(timeout, TimeoutSauce):\n            pass\n        else:\n            timeout = TimeoutSauce(connect=timeout, read=timeout)\n    \n        try:\n>           resp = conn.urlopen(\n                method=request.method,\n                url=url,\n                body=request.body,\n                headers=request.headers,\n                redirect=False,\n                assert_same_host=False,\n                preload_content=False,\n                decode_content=False,\n                retries=self.max_retries,\n                timeout=timeout,\n                chunked=chunked,\n            )\n\n..\\Community\\lib\\site-packages\\requests\\adapters.py:667: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n..\\Community\\lib\\site-packages\\urllib3\\connectionpool.py:843: in urlopen\n    retries = retries.increment(\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = Retry(total=0, connect=None, read=False, redirect=None, status=None)\nmethod = 'DELETE'\nurl = '/api/blockchain/master-slave/deletePa?id=1978749551737966594'\nresponse = None\nerror = ProxyError('Unable to connect to proxy', FileNotFoundError(2, 'No such file or directory'))\n_pool = <urllib3.connectionpool.HTTPSConnectionPool object at 0x000001D22C9D3850>\n_stacktrace = <traceback object at 0x000001D22DEC4280>\n\n    def increment(\n        self,\n        method: str | None = None,\n        url: str | None = None,\n        response: BaseHTTPResponse | None = None,\n        error: Exception | None = None,\n        _pool: ConnectionPool | None = None,\n        _stacktrace: TracebackType | None = None,\n    ) -> Self:\n        \"\"\"Return a new Retry object with incremented retry counters.\n    \n        :param response: A response object, or None, if the server did not\n            return a response.\n        :type response: :class:`~urllib3.response.BaseHTTPResponse`\n        :param Exception error: An error encountered during the request, or\n            None if the response was received successfully.\n    \n        :return: A new ``Retry`` object.\n        \"\"\"\n        if self.total is False and error:\n            # Disabled, indicate to re-raise the error.\n            raise reraise(type(error), error, _stacktrace)\n    \n        total = self.total\n        if total is not None:\n            total -= 1\n    \n        connect = self.connect\n        read = self.read\n        redirect = self.redirect\n        status_count = self.status\n        other = self.other\n        cause = \"unknown\"\n        status = None\n        redirect_location = None\n    \n        if error and self._is_connection_error(error):\n            # Connect retry?\n            if connect is False:\n                raise reraise(type(error), error, _stacktrace)\n            elif connect is not None:\n                connect -= 1\n    \n        elif error and self._is_read_error(error):\n            # Read retry?\n            if read is False or method is None or not self._is_method_retryable(method):\n                raise reraise(type(error), error, _stacktrace)\n            elif read is not None:\n                read -= 1\n    \n        elif error:\n            # Other retry?\n            if other is not None:\n                other -= 1\n    \n        elif response and response.get_redirect_location():\n            # Redirect retry?\n            if redirect is not None:\n                redirect -= 1\n            cause = \"too many redirects\"\n            response_redirect_location = response.get_redirect_location()\n            if response_redirect_location:\n                redirect_location = response_redirect_location\n            status = response.status\n    \n        else:\n            # Incrementing because of a server error like a 500 in\n            # status_forcelist and the given method is in the allowed_methods\n            cause = ResponseError.GENERIC_ERROR\n            if response and response.status:\n                if status_count is not None:\n                    status_count -= 1\n                cause = ResponseError.SPECIFIC_ERROR.format(status_code=response.status)\n                status = response.status\n    \n        history = self.history + (\n            RequestHistory(method, url, error, status, redirect_location),\n        )\n    \n        new_retry = self.new(\n            total=total,\n            connect=connect,\n            read=read,\n            redirect=redirect,\n            status=status_count,\n            other=other,\n            history=history,\n        )\n    \n        if new_retry.is_exhausted():\n            reason = error or ResponseError(cause)\n>           raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\nE           urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='dev.lgcopytrade.top', port=443): Max retries exceeded with url: /api/blockchain/master-slave/deletePa?id=1978749551737966594 (Caused by ProxyError('Unable to connect to proxy', FileNotFoundError(2, 'No such file or directory')))\n\n..\\Community\\lib\\site-packages\\urllib3\\util\\retry.py:519: MaxRetryError\n\nDuring handling of the above exception, another exception occurred:\n\nself = <template.test_cloudTrader.test_add_delete.Test_delete_batch object at 0x000001D22C6B1850>\nlogged_session = <template.commons.session.EnvironmentSession object at 0x000001D22C6C44C0>\nurl = '/blockchain/master-slave/deletePa', json_data = None\nparams = {'id': '1978749551737966594'}, sleep_seconds = 3\n\n    def send_delete_request(self, logged_session, url, json_data=None, params=None, sleep_seconds=SLEEP_SECONDS):\n        \"\"\"\n        发送DELETE请求（异常分层优化）\n    \n        :param logged_session: 已登录的会话对象\n        :param url: 请求URL\n        :param json_data: 请求体JSON数据（可选）\n        :param params: URL查询参数（可选，如{'id': '1971039114011594754'}）\n        :param sleep_seconds: 请求后等待秒数\n        :return: 响应对象\n        \"\"\"\n        method = \"DELETE\"\n        with allure.step(f\"执行 {method} 请求: {url}\"):\n            try:\n                # 处理参数，确保查询参数通过params传递而非直接拼接在url中\n                full_url = url\n                if params:\n                    # 移除URL中已存在的查询参数，避免重复\n                    parsed_url = urlparse(url)\n                    if parsed_url.query:\n                        logger.warning(f\"URL中已包含查询参数: {parsed_url.query}，将被params参数覆盖\")\n                        full_url = urlunparse(parsed_url._replace(query=''))\n    \n                # 附加请求详情到allure报告\n                self._attach_request_details(\n                    method=method,\n                    url=full_url,\n                    headers=logged_session.headers,\n                    params=params,\n                    body=json_data,\n                    is_json=True,\n                )\n    \n                # 发送DELETE请求，查询参数通过params参数传递\n>               response = logged_session.delete(\n                    full_url,\n                    json=json_data,\n                    params=params\n                )\n\ncommons\\api_base.py:336: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n..\\Community\\lib\\site-packages\\requests\\sessions.py:671: in delete\n    return self.request(\"DELETE\", url, **kwargs)\ncommons\\session.py:135: in request\n    response = super().request(method, full_url, *args, **kwargs)\n..\\Community\\lib\\site-packages\\requests\\sessions.py:589: in request\n    resp = self.send(prep, **send_kwargs)\n..\\Community\\lib\\site-packages\\requests\\sessions.py:703: in send\n    r = adapter.send(request, **kwargs)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <requests.adapters.HTTPAdapter object at 0x000001D22C6C4E80>\nrequest = <PreparedRequest [DELETE]>, stream = False\ntimeout = Timeout(connect=None, read=None, total=None), verify = True\ncert = None\nproxies = OrderedDict([('http', 'http://127.0.0.1:10809'), ('https', 'https://127.0.0.1:10809'), ('ftp', 'ftp://127.0.0.1:10809')])\n\n    def send(\n        self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None\n    ):\n        \"\"\"Sends PreparedRequest object. Returns Response object.\n    \n        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\n        :param stream: (optional) Whether to stream the request content.\n        :param timeout: (optional) How long to wait for the server to send\n            data before giving up, as a float, or a :ref:`(connect timeout,\n            read timeout) <timeouts>` tuple.\n        :type timeout: float or tuple or urllib3 Timeout object\n        :param verify: (optional) Either a boolean, in which case it controls whether\n            we verify the server's TLS certificate, or a string, in which case it\n            must be a path to a CA bundle to use\n        :param cert: (optional) Any user-provided SSL certificate to be trusted.\n        :param proxies: (optional) The proxies dictionary to apply to the request.\n        :rtype: requests.Response\n        \"\"\"\n    \n        try:\n            conn = self.get_connection_with_tls_context(\n                request, verify, proxies=proxies, cert=cert\n            )\n        except LocationValueError as e:\n            raise InvalidURL(e, request=request)\n    \n        self.cert_verify(conn, request.url, verify, cert)\n        url = self.request_url(request, proxies)\n        self.add_headers(\n            request,\n            stream=stream,\n            timeout=timeout,\n            verify=verify,\n            cert=cert,\n            proxies=proxies,\n        )\n    \n        chunked = not (request.body is None or \"Content-Length\" in request.headers)\n    \n        if isinstance(timeout, tuple):\n            try:\n                connect, read = timeout\n                timeout = TimeoutSauce(connect=connect, read=read)\n            except ValueError:\n                raise ValueError(\n                    f\"Invalid timeout {timeout}. Pass a (connect, read) timeout tuple, \"\n                    f\"or a single float to set both timeouts to the same value.\"\n                )\n        elif isinstance(timeout, TimeoutSauce):\n            pass\n        else:\n            timeout = TimeoutSauce(connect=timeout, read=timeout)\n    \n        try:\n            resp = conn.urlopen(\n                method=request.method,\n                url=url,\n                body=request.body,\n                headers=request.headers,\n                redirect=False,\n                assert_same_host=False,\n                preload_content=False,\n                decode_content=False,\n                retries=self.max_retries,\n                timeout=timeout,\n                chunked=chunked,\n            )\n    \n        except (ProtocolError, OSError) as err:\n            raise ConnectionError(err, request=request)\n    \n        except MaxRetryError as e:\n            if isinstance(e.reason, ConnectTimeoutError):\n                # TODO: Remove this in 3.0.0: see #2811\n                if not isinstance(e.reason, NewConnectionError):\n                    raise ConnectTimeout(e, request=request)\n    \n            if isinstance(e.reason, ResponseError):\n                raise RetryError(e, request=request)\n    \n            if isinstance(e.reason, _ProxyError):\n>               raise ProxyError(e, request=request)\nE               requests.exceptions.ProxyError: HTTPSConnectionPool(host='dev.lgcopytrade.top', port=443): Max retries exceeded with url: /api/blockchain/master-slave/deletePa?id=1978749551737966594 (Caused by ProxyError('Unable to connect to proxy', FileNotFoundError(2, 'No such file or directory')))\n\n..\\Community\\lib\\site-packages\\requests\\adapters.py:694: ProxyError\n\nThe above exception was the direct cause of the following exception:\n\nself = <template.test_cloudTrader.test_add_delete.Test_delete_batch object at 0x000001D22C6B1850>\naccount_info = {'account': '301392107', 'jeecg_rowkey': '1978745428095406081', 'pass_id': '1978745394211811330'}\nvar_manager = <template.commons.variable_manager.VariableManager object at 0x000001D22C6C4BE0>\nlogged_session = <template.commons.session.EnvironmentSession object at 0x000001D22C6C44C0>\ndb_transaction = <pymysql.connections.Connection object at 0x000001D22DDC7A00>\n\n    @allure.title(\"多账号批量解绑：取消订阅 + 前端解绑 + 数据库校验\")\n    @pytest.mark.parametrize(\"account_info\", get_follow_accounts_from_runtime_json())\n    def test_batch_unbind(self, account_info, var_manager, logged_session, db_transaction):\n        \"\"\"单个账号完整解绑流程：取消订阅→前端解绑→数据库校验\"\"\"\n        # 1. 执行阶段实时读取最新数据（关键步骤）\n        latest_accounts = get_follow_accounts_from_runtime_json()\n        current_account = account_info[\"account\"]\n    \n        # 2. 从最新数据中匹配当前账号\n        latest_info = next(\n            (item for item in latest_accounts if item[\"account\"] == current_account),\n            None\n        )\n        if not latest_info:\n            pytest.fail(f\"当前账号 {current_account} 在最新JSON中未找到\")\n    \n        # 3. 强制使用最新数据（覆盖参数化的旧数据）\n        account = latest_info[\"account\"]\n        pass_id = latest_info[\"pass_id\"]\n        jeecg_rowkey = latest_info[\"jeecg_rowkey\"]\n    \n        # 打印数据对比日志（用于调试新旧数据差异）\n        logging.info(f\"\\n[数据对比] 账号：{account}\"\n                     f\"\\n- 执行阶段最新jeecg_rowkey：{jeecg_rowkey}\"\n                     f\"\\n- 参数化阶段旧jeecg_rowkey：{account_info['jeecg_rowkey']}\")\n    \n        allure.dynamic.description(f\"当前解绑账号：{account}（pass_id：{pass_id}）\")\n    \n        try:\n            # -------------------------- 步骤1：取消订阅（使用最新jeecg_rowkey） --------------------------\n            with allure.step(f\"1. 取消订阅（账号：{account}）\"):\n                params = {\"id\": jeecg_rowkey}\n>               response = self.send_delete_request(\n                    logged_session,\n                    '/blockchain/master-slave/deletePa',\n                    params=params\n                )\n\ntest_cloudTrader\\test_add_delete.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <template.test_cloudTrader.test_add_delete.Test_delete_batch object at 0x000001D22C6B1850>\nlogged_session = <template.commons.session.EnvironmentSession object at 0x000001D22C6C44C0>\nurl = '/blockchain/master-slave/deletePa', json_data = None\nparams = {'id': '1978749551737966594'}, sleep_seconds = 3\n\n    def send_delete_request(self, logged_session, url, json_data=None, params=None, sleep_seconds=SLEEP_SECONDS):\n        \"\"\"\n        发送DELETE请求（异常分层优化）\n    \n        :param logged_session: 已登录的会话对象\n        :param url: 请求URL\n        :param json_data: 请求体JSON数据（可选）\n        :param params: URL查询参数（可选，如{'id': '1971039114011594754'}）\n        :param sleep_seconds: 请求后等待秒数\n        :return: 响应对象\n        \"\"\"\n        method = \"DELETE\"\n        with allure.step(f\"执行 {method} 请求: {url}\"):\n            try:\n                # 处理参数，确保查询参数通过params传递而非直接拼接在url中\n                full_url = url\n                if params:\n                    # 移除URL中已存在的查询参数，避免重复\n                    parsed_url = urlparse(url)\n                    if parsed_url.query:\n                        logger.warning(f\"URL中已包含查询参数: {parsed_url.query}，将被params参数覆盖\")\n                        full_url = urlunparse(parsed_url._replace(query=''))\n    \n                # 附加请求详情到allure报告\n                self._attach_request_details(\n                    method=method,\n                    url=full_url,\n                    headers=logged_session.headers,\n                    params=params,\n                    body=json_data,\n                    is_json=True,\n                )\n    \n                # 发送DELETE请求，查询参数通过params参数传递\n                response = logged_session.delete(\n                    full_url,\n                    json=json_data,\n                    params=params\n                )\n    \n                # 记录请求日志\n                logger.info(\n                    f\"[{self._get_current_time()}] {method}请求: {full_url} \"\n                    f\"| 参数: {params} | 数据: {json_data} | 状态码: {response.status_code}\"\n                )\n    \n                # 附加响应详情到allure报告\n                self._attach_response_details(response)\n    \n                # 请求后等待\n                if sleep_seconds > 0:\n                    time.sleep(sleep_seconds)\n    \n                return response\n    \n            except (SSLError, ConnectionError, Timeout) as e:\n                error_type = \"网络层异常\"\n                with allure.step(f\"{method} 请求{error_type}\"):\n                    self._attach_request_details(\n                        method=method,\n                        url=url,\n                        headers=logged_session.headers,\n                        params=params,\n                        body=json_data,\n                        is_json=True,\n                    )\n                    error_detail = (\n                        f\"{error_type}: {str(e)}\\n\"\n                        f\"URL: {url}\\n\"\n                        f\"查询参数: {params}\\n\"\n                        f\"请求头: {logged_session.headers}\\n\"\n                        f\"请求体: {json_data}\"\n                    )\n                    allure.attach(error_detail, f\"{error_type}详情\", allure.attachment_type.TEXT)\n                logger.error(\n                    f\"[{self._get_current_time()}] {method}请求{error_type}: {str(e)} \"\n                    f\"| URL: {url} | 参数: {params}\",\n                    exc_info=True\n                )\n>               raise ConnectionError(f\"Failed: {method}请求{error_type}（{str(e)[:1000]}）\") from e\nE               requests.exceptions.ConnectionError: Failed: DELETE请求网络层异常（HTTPSConnectionPool(host='dev.lgcopytrade.top', port=443): Max retries exceeded with url: /api/blockchain/master-slave/deletePa?id=1978749551737966594 (Caused by ProxyError('Unable to connect to proxy', FileNotFoundError(2, 'No such file or directory')))）\n\ncommons\\api_base.py:381: ConnectionError\n\nDuring handling of the above exception, another exception occurred:\n\nself = <template.test_cloudTrader.test_add_delete.Test_delete_batch object at 0x000001D22C6B1850>\naccount_info = {'account': '301392107', 'jeecg_rowkey': '1978745428095406081', 'pass_id': '1978745394211811330'}\nvar_manager = <template.commons.variable_manager.VariableManager object at 0x000001D22C6C4BE0>\nlogged_session = <template.commons.session.EnvironmentSession object at 0x000001D22C6C44C0>\ndb_transaction = <pymysql.connections.Connection object at 0x000001D22DDC7A00>\n\n    @allure.title(\"多账号批量解绑：取消订阅 + 前端解绑 + 数据库校验\")\n    @pytest.mark.parametrize(\"account_info\", get_follow_accounts_from_runtime_json())\n    def test_batch_unbind(self, account_info, var_manager, logged_session, db_transaction):\n        \"\"\"单个账号完整解绑流程：取消订阅→前端解绑→数据库校验\"\"\"\n        # 1. 执行阶段实时读取最新数据（关键步骤）\n        latest_accounts = get_follow_accounts_from_runtime_json()\n        current_account = account_info[\"account\"]\n    \n        # 2. 从最新数据中匹配当前账号\n        latest_info = next(\n            (item for item in latest_accounts if item[\"account\"] == current_account),\n            None\n        )\n        if not latest_info:\n            pytest.fail(f\"当前账号 {current_account} 在最新JSON中未找到\")\n    \n        # 3. 强制使用最新数据（覆盖参数化的旧数据）\n        account = latest_info[\"account\"]\n        pass_id = latest_info[\"pass_id\"]\n        jeecg_rowkey = latest_info[\"jeecg_rowkey\"]\n    \n        # 打印数据对比日志（用于调试新旧数据差异）\n        logging.info(f\"\\n[数据对比] 账号：{account}\"\n                     f\"\\n- 执行阶段最新jeecg_rowkey：{jeecg_rowkey}\"\n                     f\"\\n- 参数化阶段旧jeecg_rowkey：{account_info['jeecg_rowkey']}\")\n    \n        allure.dynamic.description(f\"当前解绑账号：{account}（pass_id：{pass_id}）\")\n    \n        try:\n            # -------------------------- 步骤1：取消订阅（使用最新jeecg_rowkey） --------------------------\n            with allure.step(f\"1. 取消订阅（账号：{account}）\"):\n                params = {\"id\": jeecg_rowkey}\n                response = self.send_delete_request(\n                    logged_session,\n                    '/blockchain/master-slave/deletePa',\n                    params=params\n                )\n    \n                self.assert_json_value(\n                    response,\n                    \"$.success\",\n                    True,\n                    f\"账号[{account}]取消订阅失败，响应：{response.text[:500]}\"\n                )\n                allure.attach(str(params), f\"{account}取消订阅参数\", allure.attachment_type.TEXT)\n                allure.attach(response.text, f\"{account}取消订阅响应\", allure.attachment_type.JSON)\n    \n            # -------------------------- 步骤2：前端-跟单账号解绑（使用最新pass_id） --------------------------\n            with allure.step(f\"2. 前端解绑跟单账号（账号：{account}）\"):\n                token_top = var_manager.get_variable(\"token_top\")\n                assert token_top, \"未获取到前端token（token_top）\"\n    \n                URL_TOP = var_manager.get_variable(\"URL_TOP\")\n                Host = var_manager.get_variable(\"Hosttop\")\n                url = f\"{URL_TOP}/blockchain/account/unbind?traderId={pass_id}\"\n                payload = json.dumps({})\n                headers = {\n                    'priority': 'u=1, i',\n                    'x-access-token': token_top,\n                    'User-Agent': 'Apifox/1.0.0 (https://apifox.com)',\n                    'content-type': 'application/json',\n                    'Accept': '*/*',\n                    'Host': Host,\n                    'Connection': 'keep-alive'\n                }\n    \n                response = requests.request(\"POST\", url, headers=headers, data=payload)\n                self.assert_json_value(\n                    response,\n                    \"$.success\",\n                    True,\n                    f\"账号[{account}]前端解绑失败，响应：{response.text[:500]}\"\n                )\n                allure.attach(url, f\"{account}解绑URL\", allure.attachment_type.TEXT)\n                allure.attach(json.dumps(headers), f\"{account}解绑请求头\", allure.attachment_type.JSON)\n                allure.attach(response.text, f\"{account}解绑响应\", allure.attachment_type.JSON)\n    \n            # -------------------------- 步骤3：数据库校验-账号状态为UNBIND --------------------------\n            with allure.step(f\"3. 数据库校验（账号：{account}）\"):\n                sql = \"\"\"\n                    SELECT status\n                    FROM bchain_trader\n                    WHERE id = %s\n                \"\"\"\n                db_data = self.query_database(\n                    db_transaction=db_transaction,\n                    sql=sql,\n                    params=(pass_id,)\n                )\n    \n                assert len(db_data) > 0, f\"数据库未查询到账号[{account}]（pass_id：{pass_id}）\"\n                actual_status = db_data[0][\"status\"]\n                assert actual_status == \"UNBIND\", \\\n                    f\"账号[{account}]解绑状态异常：实际={actual_status}，期望=UNBIND\"\n    \n                logging.info(f\"账号[{account}]解绑完成，数据库状态校验通过\")\n    \n        except Exception as e:\n            error_msg = f\"账号[{account}]解绑失败：{str(e)[:500]}\"\n            logging.error(error_msg, exc_info=True)\n            allure.attach(error_msg, f\"{account}解绑失败详情\", allure.attachment_type.TEXT)\n>           pytest.fail(error_msg)\nE           Failed: 账号[301392107]解绑失败：Failed: DELETE请求网络层异常（HTTPSConnectionPool(host='dev.lgcopytrade.top', port=443): Max retries exceeded with url: /api/blockchain/master-slave/deletePa?id=1978749551737966594 (Caused by ProxyError('Unable to connect to proxy', FileNotFoundError(2, 'No such file or directory')))）\n\ntest_cloudTrader\\test_add_delete.py:189: Failed",
  "flaky" : false,
  "newFailed" : false,
  "beforeStages" : [ {
    "name" : "db",
    "time" : {
      "start" : 1760605837124,
      "stop" : 1760605837540,
      "duration" : 416
    },
    "status" : "passed",
    "steps" : [ ],
    "attachments" : [ ],
    "parameters" : [ ],
    "hasContent" : false,
    "stepsCount" : 0,
    "attachmentsCount" : 0,
    "shouldDisplayMessage" : false
  }, {
    "name" : "db_transaction",
    "time" : {
      "start" : 1760605837540,
      "stop" : 1760605837540,
      "duration" : 0
    },
    "status" : "passed",
    "steps" : [ ],
    "attachments" : [ ],
    "parameters" : [ ],
    "hasContent" : false,
    "stepsCount" : 0,
    "attachmentsCount" : 0,
    "shouldDisplayMessage" : false
  } ],
  "testStage" : {
    "description" : "当前解绑账号：301392107（pass_id：1978749475881971714）",
    "status" : "failed",
    "statusMessage" : "Failed: 账号[301392107]解绑失败：Failed: DELETE请求网络层异常（HTTPSConnectionPool(host='dev.lgcopytrade.top', port=443): Max retries exceeded with url: /api/blockchain/master-slave/deletePa?id=1978749551737966594 (Caused by ProxyError('Unable to connect to proxy', FileNotFoundError(2, 'No such file or directory')))）",
    "statusTrace" : "self = <urllib3.connectionpool.HTTPSConnectionPool object at 0x000001D22C9D3850>\nmethod = 'DELETE'\nurl = '/api/blockchain/master-slave/deletePa?id=1978749551737966594'\nbody = b'null'\nheaders = {'User-Agent': 'python-requests/2.32.4', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-aliv...nant_id': '0', 'Content-Type': 'application/json; charset=utf-8', 'Host': 'dev.lgcopytrade.top', 'Content-Length': '4'}\nretries = Retry(total=0, connect=None, read=False, redirect=None, status=None)\nredirect = False, assert_same_host = False\ntimeout = Timeout(connect=None, read=None, total=None), pool_timeout = None\nrelease_conn = False, chunked = False, body_pos = None, preload_content = False\ndecode_content = False, response_kw = {}\nparsed_url = Url(scheme=None, auth=None, host=None, port=None, path='/api/blockchain/master-slave/deletePa', query='id=1978749551737966594', fragment=None)\ndestination_scheme = None, conn = None, release_this_conn = True\nhttp_tunnel_required = True, err = None, clean_exit = False\n\n    def urlopen(  # type: ignore[override]\n        self,\n        method: str,\n        url: str,\n        body: _TYPE_BODY | None = None,\n        headers: typing.Mapping[str, str] | None = None,\n        retries: Retry | bool | int | None = None,\n        redirect: bool = True,\n        assert_same_host: bool = True,\n        timeout: _TYPE_TIMEOUT = _DEFAULT_TIMEOUT,\n        pool_timeout: int | None = None,\n        release_conn: bool | None = None,\n        chunked: bool = False,\n        body_pos: _TYPE_BODY_POSITION | None = None,\n        preload_content: bool = True,\n        decode_content: bool = True,\n        **response_kw: typing.Any,\n    ) -> BaseHTTPResponse:\n        \"\"\"\n        Get a connection from the pool and perform an HTTP request. This is the\n        lowest level call for making a request, so you'll need to specify all\n        the raw details.\n    \n        .. note::\n    \n           More commonly, it's appropriate to use a convenience method\n           such as :meth:`request`.\n    \n        .. note::\n    \n           `release_conn` will only behave as expected if\n           `preload_content=False` because we want to make\n           `preload_content=False` the default behaviour someday soon without\n           breaking backwards compatibility.\n    \n        :param method:\n            HTTP request method (such as GET, POST, PUT, etc.)\n    \n        :param url:\n            The URL to perform the request on.\n    \n        :param body:\n            Data to send in the request body, either :class:`str`, :class:`bytes`,\n            an iterable of :class:`str`/:class:`bytes`, or a file-like object.\n    \n        :param headers:\n            Dictionary of custom headers to send, such as User-Agent,\n            If-None-Match, etc. If None, pool headers are used. If provided,\n            these headers completely replace any pool-specific headers.\n    \n        :param retries:\n            Configure the number of retries to allow before raising a\n            :class:`~urllib3.exceptions.MaxRetryError` exception.\n    \n            If ``None`` (default) will retry 3 times, see ``Retry.DEFAULT``. Pass a\n            :class:`~urllib3.util.retry.Retry` object for fine-grained control\n            over different types of retries.\n            Pass an integer number to retry connection errors that many times,\n            but no other types of errors. Pass zero to never retry.\n    \n            If ``False``, then retries are disabled and any exception is raised\n            immediately. Also, instead of raising a MaxRetryError on redirects,\n            the redirect response will be returned.\n    \n        :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.\n    \n        :param redirect:\n            If True, automatically handle redirects (status codes 301, 302,\n            303, 307, 308). Each redirect counts as a retry. Disabling retries\n            will disable redirect, too.\n    \n        :param assert_same_host:\n            If ``True``, will make sure that the host of the pool requests is\n            consistent else will raise HostChangedError. When ``False``, you can\n            use the pool on an HTTP proxy and request foreign hosts.\n    \n        :param timeout:\n            If specified, overrides the default timeout for this one\n            request. It may be a float (in seconds) or an instance of\n            :class:`urllib3.util.Timeout`.\n    \n        :param pool_timeout:\n            If set and the pool is set to block=True, then this method will\n            block for ``pool_timeout`` seconds and raise EmptyPoolError if no\n            connection is available within the time period.\n    \n        :param bool preload_content:\n            If True, the response's body will be preloaded into memory.\n    \n        :param bool decode_content:\n            If True, will attempt to decode the body based on the\n            'content-encoding' header.\n    \n        :param release_conn:\n            If False, then the urlopen call will not release the connection\n            back into the pool once a response is received (but will release if\n            you read the entire contents of the response such as when\n            `preload_content=True`). This is useful if you're not preloading\n            the response's content immediately. You will need to call\n            ``r.release_conn()`` on the response ``r`` to return the connection\n            back into the pool. If None, it takes the value of ``preload_content``\n            which defaults to ``True``.\n    \n        :param bool chunked:\n            If True, urllib3 will send the body using chunked transfer\n            encoding. Otherwise, urllib3 will send the body using the standard\n            content-length form. Defaults to False.\n    \n        :param int body_pos:\n            Position to seek to in file-like body in the event of a retry or\n            redirect. Typically this won't need to be set because urllib3 will\n            auto-populate the value when needed.\n        \"\"\"\n        parsed_url = parse_url(url)\n        destination_scheme = parsed_url.scheme\n    \n        if headers is None:\n            headers = self.headers\n    \n        if not isinstance(retries, Retry):\n            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)\n    \n        if release_conn is None:\n            release_conn = preload_content\n    \n        # Check host\n        if assert_same_host and not self.is_same_host(url):\n            raise HostChangedError(self, url, retries)\n    \n        # Ensure that the URL we're connecting to is properly encoded\n        if url.startswith(\"/\"):\n            url = to_str(_encode_target(url))\n        else:\n            url = to_str(parsed_url.url)\n    \n        conn = None\n    \n        # Track whether `conn` needs to be released before\n        # returning/raising/recursing. Update this variable if necessary, and\n        # leave `release_conn` constant throughout the function. That way, if\n        # the function recurses, the original value of `release_conn` will be\n        # passed down into the recursive call, and its value will be respected.\n        #\n        # See issue #651 [1] for details.\n        #\n        # [1] <https://github.com/urllib3/urllib3/issues/651>\n        release_this_conn = release_conn\n    \n        http_tunnel_required = connection_requires_http_tunnel(\n            self.proxy, self.proxy_config, destination_scheme\n        )\n    \n        # Merge the proxy headers. Only done when not using HTTP CONNECT. We\n        # have to copy the headers dict so we can safely change it without those\n        # changes being reflected in anyone else's copy.\n        if not http_tunnel_required:\n            headers = headers.copy()  # type: ignore[attr-defined]\n            headers.update(self.proxy_headers)  # type: ignore[union-attr]\n    \n        # Must keep the exception bound to a separate variable or else Python 3\n        # complains about UnboundLocalError.\n        err = None\n    \n        # Keep track of whether we cleanly exited the except block. This\n        # ensures we do proper cleanup in finally.\n        clean_exit = False\n    \n        # Rewind body position, if needed. Record current position\n        # for future rewinds in the event of a redirect/retry.\n        body_pos = set_file_position(body, body_pos)\n    \n        try:\n            # Request a connection from the queue.\n            timeout_obj = self._get_timeout(timeout)\n            conn = self._get_conn(timeout=pool_timeout)\n    \n            conn.timeout = timeout_obj.connect_timeout  # type: ignore[assignment]\n    \n            # Is this a closed/new connection that requires CONNECT tunnelling?\n            if self.proxy is not None and http_tunnel_required and conn.is_closed:\n                try:\n>                   self._prepare_proxy(conn)\n\n..\\Community\\lib\\site-packages\\urllib3\\connectionpool.py:775: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n..\\Community\\lib\\site-packages\\urllib3\\connectionpool.py:1044: in _prepare_proxy\n    conn.connect()\n..\\Community\\lib\\site-packages\\urllib3\\connection.py:702: in connect\n    self.sock = sock = self._connect_tls_proxy(self.host, sock)\n..\\Community\\lib\\site-packages\\urllib3\\connection.py:802: in _connect_tls_proxy\n    sock_and_verified = _ssl_wrap_socket_and_match_hostname(\n..\\Community\\lib\\site-packages\\urllib3\\connection.py:909: in _ssl_wrap_socket_and_match_hostname\n    ssl_sock = ssl_wrap_socket(\n..\\Community\\lib\\site-packages\\urllib3\\util\\ssl_.py:469: in ssl_wrap_socket\n    ssl_sock = _ssl_wrap_socket_impl(sock, context, tls_in_tls, server_hostname)\n..\\Community\\lib\\site-packages\\urllib3\\util\\ssl_.py:513: in _ssl_wrap_socket_impl\n    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)\nD:\\python_tools\\python\\lib\\ssl.py:500: in wrap_socket\n    return self.sslsocket_class._create(\nD:\\python_tools\\python\\lib\\ssl.py:1040: in _create\n    self.do_handshake()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <ssl.SSLSocket [closed] fd=-1, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0>\nblock = False\n\n    @_sslcopydoc\n    def do_handshake(self, block=False):\n        self._check_connected()\n        timeout = self.gettimeout()\n        try:\n            if timeout == 0.0 and block:\n                self.settimeout(None)\n>           self._sslobj.do_handshake()\nE           FileNotFoundError: [Errno 2] No such file or directory\n\nD:\\python_tools\\python\\lib\\ssl.py:1309: FileNotFoundError\n\nThe above exception was the direct cause of the following exception:\nTraceback (most recent call last):\n  File \"D:\\pycharm_test\\Community\\lib\\site-packages\\urllib3\\connectionpool.py\", line 775, in urlopen\n    self._prepare_proxy(conn)\n  File \"D:\\pycharm_test\\Community\\lib\\site-packages\\urllib3\\connectionpool.py\", line 1044, in _prepare_proxy\n    conn.connect()\n  File \"D:\\pycharm_test\\Community\\lib\\site-packages\\urllib3\\connection.py\", line 702, in connect\n    self.sock = sock = self._connect_tls_proxy(self.host, sock)\n  File \"D:\\pycharm_test\\Community\\lib\\site-packages\\urllib3\\connection.py\", line 802, in _connect_tls_proxy\n    sock_and_verified = _ssl_wrap_socket_and_match_hostname(\n  File \"D:\\pycharm_test\\Community\\lib\\site-packages\\urllib3\\connection.py\", line 909, in _ssl_wrap_socket_and_match_hostname\n    ssl_sock = ssl_wrap_socket(\n  File \"D:\\pycharm_test\\Community\\lib\\site-packages\\urllib3\\util\\ssl_.py\", line 469, in ssl_wrap_socket\n    ssl_sock = _ssl_wrap_socket_impl(sock, context, tls_in_tls, server_hostname)\n  File \"D:\\pycharm_test\\Community\\lib\\site-packages\\urllib3\\util\\ssl_.py\", line 513, in _ssl_wrap_socket_impl\n    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)\n  File \"D:\\python_tools\\python\\lib\\ssl.py\", line 500, in wrap_socket\n    return self.sslsocket_class._create(\n  File \"D:\\python_tools\\python\\lib\\ssl.py\", line 1040, in _create\n    self.do_handshake()\n  File \"D:\\python_tools\\python\\lib\\ssl.py\", line 1309, in do_handshake\n    self._sslobj.do_handshake()\nFileNotFoundError: [Errno 2] No such file or directory\n\nThe above exception was the direct cause of the following exception:\n\nurllib3.exceptions.ProxyError: ('Unable to connect to proxy', FileNotFoundError(2, 'No such file or directory'))\n\nThe above exception was the direct cause of the following exception:\n\nself = <requests.adapters.HTTPAdapter object at 0x000001D22C6C4E80>\nrequest = <PreparedRequest [DELETE]>, stream = False\ntimeout = Timeout(connect=None, read=None, total=None), verify = True\ncert = None\nproxies = OrderedDict([('http', 'http://127.0.0.1:10809'), ('https', 'https://127.0.0.1:10809'), ('ftp', 'ftp://127.0.0.1:10809')])\n\n    def send(\n        self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None\n    ):\n        \"\"\"Sends PreparedRequest object. Returns Response object.\n    \n        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\n        :param stream: (optional) Whether to stream the request content.\n        :param timeout: (optional) How long to wait for the server to send\n            data before giving up, as a float, or a :ref:`(connect timeout,\n            read timeout) <timeouts>` tuple.\n        :type timeout: float or tuple or urllib3 Timeout object\n        :param verify: (optional) Either a boolean, in which case it controls whether\n            we verify the server's TLS certificate, or a string, in which case it\n            must be a path to a CA bundle to use\n        :param cert: (optional) Any user-provided SSL certificate to be trusted.\n        :param proxies: (optional) The proxies dictionary to apply to the request.\n        :rtype: requests.Response\n        \"\"\"\n    \n        try:\n            conn = self.get_connection_with_tls_context(\n                request, verify, proxies=proxies, cert=cert\n            )\n        except LocationValueError as e:\n            raise InvalidURL(e, request=request)\n    \n        self.cert_verify(conn, request.url, verify, cert)\n        url = self.request_url(request, proxies)\n        self.add_headers(\n            request,\n            stream=stream,\n            timeout=timeout,\n            verify=verify,\n            cert=cert,\n            proxies=proxies,\n        )\n    \n        chunked = not (request.body is None or \"Content-Length\" in request.headers)\n    \n        if isinstance(timeout, tuple):\n            try:\n                connect, read = timeout\n                timeout = TimeoutSauce(connect=connect, read=read)\n            except ValueError:\n                raise ValueError(\n                    f\"Invalid timeout {timeout}. Pass a (connect, read) timeout tuple, \"\n                    f\"or a single float to set both timeouts to the same value.\"\n                )\n        elif isinstance(timeout, TimeoutSauce):\n            pass\n        else:\n            timeout = TimeoutSauce(connect=timeout, read=timeout)\n    \n        try:\n>           resp = conn.urlopen(\n                method=request.method,\n                url=url,\n                body=request.body,\n                headers=request.headers,\n                redirect=False,\n                assert_same_host=False,\n                preload_content=False,\n                decode_content=False,\n                retries=self.max_retries,\n                timeout=timeout,\n                chunked=chunked,\n            )\n\n..\\Community\\lib\\site-packages\\requests\\adapters.py:667: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n..\\Community\\lib\\site-packages\\urllib3\\connectionpool.py:843: in urlopen\n    retries = retries.increment(\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = Retry(total=0, connect=None, read=False, redirect=None, status=None)\nmethod = 'DELETE'\nurl = '/api/blockchain/master-slave/deletePa?id=1978749551737966594'\nresponse = None\nerror = ProxyError('Unable to connect to proxy', FileNotFoundError(2, 'No such file or directory'))\n_pool = <urllib3.connectionpool.HTTPSConnectionPool object at 0x000001D22C9D3850>\n_stacktrace = <traceback object at 0x000001D22DEC4280>\n\n    def increment(\n        self,\n        method: str | None = None,\n        url: str | None = None,\n        response: BaseHTTPResponse | None = None,\n        error: Exception | None = None,\n        _pool: ConnectionPool | None = None,\n        _stacktrace: TracebackType | None = None,\n    ) -> Self:\n        \"\"\"Return a new Retry object with incremented retry counters.\n    \n        :param response: A response object, or None, if the server did not\n            return a response.\n        :type response: :class:`~urllib3.response.BaseHTTPResponse`\n        :param Exception error: An error encountered during the request, or\n            None if the response was received successfully.\n    \n        :return: A new ``Retry`` object.\n        \"\"\"\n        if self.total is False and error:\n            # Disabled, indicate to re-raise the error.\n            raise reraise(type(error), error, _stacktrace)\n    \n        total = self.total\n        if total is not None:\n            total -= 1\n    \n        connect = self.connect\n        read = self.read\n        redirect = self.redirect\n        status_count = self.status\n        other = self.other\n        cause = \"unknown\"\n        status = None\n        redirect_location = None\n    \n        if error and self._is_connection_error(error):\n            # Connect retry?\n            if connect is False:\n                raise reraise(type(error), error, _stacktrace)\n            elif connect is not None:\n                connect -= 1\n    \n        elif error and self._is_read_error(error):\n            # Read retry?\n            if read is False or method is None or not self._is_method_retryable(method):\n                raise reraise(type(error), error, _stacktrace)\n            elif read is not None:\n                read -= 1\n    \n        elif error:\n            # Other retry?\n            if other is not None:\n                other -= 1\n    \n        elif response and response.get_redirect_location():\n            # Redirect retry?\n            if redirect is not None:\n                redirect -= 1\n            cause = \"too many redirects\"\n            response_redirect_location = response.get_redirect_location()\n            if response_redirect_location:\n                redirect_location = response_redirect_location\n            status = response.status\n    \n        else:\n            # Incrementing because of a server error like a 500 in\n            # status_forcelist and the given method is in the allowed_methods\n            cause = ResponseError.GENERIC_ERROR\n            if response and response.status:\n                if status_count is not None:\n                    status_count -= 1\n                cause = ResponseError.SPECIFIC_ERROR.format(status_code=response.status)\n                status = response.status\n    \n        history = self.history + (\n            RequestHistory(method, url, error, status, redirect_location),\n        )\n    \n        new_retry = self.new(\n            total=total,\n            connect=connect,\n            read=read,\n            redirect=redirect,\n            status=status_count,\n            other=other,\n            history=history,\n        )\n    \n        if new_retry.is_exhausted():\n            reason = error or ResponseError(cause)\n>           raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\nE           urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='dev.lgcopytrade.top', port=443): Max retries exceeded with url: /api/blockchain/master-slave/deletePa?id=1978749551737966594 (Caused by ProxyError('Unable to connect to proxy', FileNotFoundError(2, 'No such file or directory')))\n\n..\\Community\\lib\\site-packages\\urllib3\\util\\retry.py:519: MaxRetryError\n\nDuring handling of the above exception, another exception occurred:\n\nself = <template.test_cloudTrader.test_add_delete.Test_delete_batch object at 0x000001D22C6B1850>\nlogged_session = <template.commons.session.EnvironmentSession object at 0x000001D22C6C44C0>\nurl = '/blockchain/master-slave/deletePa', json_data = None\nparams = {'id': '1978749551737966594'}, sleep_seconds = 3\n\n    def send_delete_request(self, logged_session, url, json_data=None, params=None, sleep_seconds=SLEEP_SECONDS):\n        \"\"\"\n        发送DELETE请求（异常分层优化）\n    \n        :param logged_session: 已登录的会话对象\n        :param url: 请求URL\n        :param json_data: 请求体JSON数据（可选）\n        :param params: URL查询参数（可选，如{'id': '1971039114011594754'}）\n        :param sleep_seconds: 请求后等待秒数\n        :return: 响应对象\n        \"\"\"\n        method = \"DELETE\"\n        with allure.step(f\"执行 {method} 请求: {url}\"):\n            try:\n                # 处理参数，确保查询参数通过params传递而非直接拼接在url中\n                full_url = url\n                if params:\n                    # 移除URL中已存在的查询参数，避免重复\n                    parsed_url = urlparse(url)\n                    if parsed_url.query:\n                        logger.warning(f\"URL中已包含查询参数: {parsed_url.query}，将被params参数覆盖\")\n                        full_url = urlunparse(parsed_url._replace(query=''))\n    \n                # 附加请求详情到allure报告\n                self._attach_request_details(\n                    method=method,\n                    url=full_url,\n                    headers=logged_session.headers,\n                    params=params,\n                    body=json_data,\n                    is_json=True,\n                )\n    \n                # 发送DELETE请求，查询参数通过params参数传递\n>               response = logged_session.delete(\n                    full_url,\n                    json=json_data,\n                    params=params\n                )\n\ncommons\\api_base.py:336: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n..\\Community\\lib\\site-packages\\requests\\sessions.py:671: in delete\n    return self.request(\"DELETE\", url, **kwargs)\ncommons\\session.py:135: in request\n    response = super().request(method, full_url, *args, **kwargs)\n..\\Community\\lib\\site-packages\\requests\\sessions.py:589: in request\n    resp = self.send(prep, **send_kwargs)\n..\\Community\\lib\\site-packages\\requests\\sessions.py:703: in send\n    r = adapter.send(request, **kwargs)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <requests.adapters.HTTPAdapter object at 0x000001D22C6C4E80>\nrequest = <PreparedRequest [DELETE]>, stream = False\ntimeout = Timeout(connect=None, read=None, total=None), verify = True\ncert = None\nproxies = OrderedDict([('http', 'http://127.0.0.1:10809'), ('https', 'https://127.0.0.1:10809'), ('ftp', 'ftp://127.0.0.1:10809')])\n\n    def send(\n        self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None\n    ):\n        \"\"\"Sends PreparedRequest object. Returns Response object.\n    \n        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\n        :param stream: (optional) Whether to stream the request content.\n        :param timeout: (optional) How long to wait for the server to send\n            data before giving up, as a float, or a :ref:`(connect timeout,\n            read timeout) <timeouts>` tuple.\n        :type timeout: float or tuple or urllib3 Timeout object\n        :param verify: (optional) Either a boolean, in which case it controls whether\n            we verify the server's TLS certificate, or a string, in which case it\n            must be a path to a CA bundle to use\n        :param cert: (optional) Any user-provided SSL certificate to be trusted.\n        :param proxies: (optional) The proxies dictionary to apply to the request.\n        :rtype: requests.Response\n        \"\"\"\n    \n        try:\n            conn = self.get_connection_with_tls_context(\n                request, verify, proxies=proxies, cert=cert\n            )\n        except LocationValueError as e:\n            raise InvalidURL(e, request=request)\n    \n        self.cert_verify(conn, request.url, verify, cert)\n        url = self.request_url(request, proxies)\n        self.add_headers(\n            request,\n            stream=stream,\n            timeout=timeout,\n            verify=verify,\n            cert=cert,\n            proxies=proxies,\n        )\n    \n        chunked = not (request.body is None or \"Content-Length\" in request.headers)\n    \n        if isinstance(timeout, tuple):\n            try:\n                connect, read = timeout\n                timeout = TimeoutSauce(connect=connect, read=read)\n            except ValueError:\n                raise ValueError(\n                    f\"Invalid timeout {timeout}. Pass a (connect, read) timeout tuple, \"\n                    f\"or a single float to set both timeouts to the same value.\"\n                )\n        elif isinstance(timeout, TimeoutSauce):\n            pass\n        else:\n            timeout = TimeoutSauce(connect=timeout, read=timeout)\n    \n        try:\n            resp = conn.urlopen(\n                method=request.method,\n                url=url,\n                body=request.body,\n                headers=request.headers,\n                redirect=False,\n                assert_same_host=False,\n                preload_content=False,\n                decode_content=False,\n                retries=self.max_retries,\n                timeout=timeout,\n                chunked=chunked,\n            )\n    \n        except (ProtocolError, OSError) as err:\n            raise ConnectionError(err, request=request)\n    \n        except MaxRetryError as e:\n            if isinstance(e.reason, ConnectTimeoutError):\n                # TODO: Remove this in 3.0.0: see #2811\n                if not isinstance(e.reason, NewConnectionError):\n                    raise ConnectTimeout(e, request=request)\n    \n            if isinstance(e.reason, ResponseError):\n                raise RetryError(e, request=request)\n    \n            if isinstance(e.reason, _ProxyError):\n>               raise ProxyError(e, request=request)\nE               requests.exceptions.ProxyError: HTTPSConnectionPool(host='dev.lgcopytrade.top', port=443): Max retries exceeded with url: /api/blockchain/master-slave/deletePa?id=1978749551737966594 (Caused by ProxyError('Unable to connect to proxy', FileNotFoundError(2, 'No such file or directory')))\n\n..\\Community\\lib\\site-packages\\requests\\adapters.py:694: ProxyError\n\nThe above exception was the direct cause of the following exception:\n\nself = <template.test_cloudTrader.test_add_delete.Test_delete_batch object at 0x000001D22C6B1850>\naccount_info = {'account': '301392107', 'jeecg_rowkey': '1978745428095406081', 'pass_id': '1978745394211811330'}\nvar_manager = <template.commons.variable_manager.VariableManager object at 0x000001D22C6C4BE0>\nlogged_session = <template.commons.session.EnvironmentSession object at 0x000001D22C6C44C0>\ndb_transaction = <pymysql.connections.Connection object at 0x000001D22DDC7A00>\n\n    @allure.title(\"多账号批量解绑：取消订阅 + 前端解绑 + 数据库校验\")\n    @pytest.mark.parametrize(\"account_info\", get_follow_accounts_from_runtime_json())\n    def test_batch_unbind(self, account_info, var_manager, logged_session, db_transaction):\n        \"\"\"单个账号完整解绑流程：取消订阅→前端解绑→数据库校验\"\"\"\n        # 1. 执行阶段实时读取最新数据（关键步骤）\n        latest_accounts = get_follow_accounts_from_runtime_json()\n        current_account = account_info[\"account\"]\n    \n        # 2. 从最新数据中匹配当前账号\n        latest_info = next(\n            (item for item in latest_accounts if item[\"account\"] == current_account),\n            None\n        )\n        if not latest_info:\n            pytest.fail(f\"当前账号 {current_account} 在最新JSON中未找到\")\n    \n        # 3. 强制使用最新数据（覆盖参数化的旧数据）\n        account = latest_info[\"account\"]\n        pass_id = latest_info[\"pass_id\"]\n        jeecg_rowkey = latest_info[\"jeecg_rowkey\"]\n    \n        # 打印数据对比日志（用于调试新旧数据差异）\n        logging.info(f\"\\n[数据对比] 账号：{account}\"\n                     f\"\\n- 执行阶段最新jeecg_rowkey：{jeecg_rowkey}\"\n                     f\"\\n- 参数化阶段旧jeecg_rowkey：{account_info['jeecg_rowkey']}\")\n    \n        allure.dynamic.description(f\"当前解绑账号：{account}（pass_id：{pass_id}）\")\n    \n        try:\n            # -------------------------- 步骤1：取消订阅（使用最新jeecg_rowkey） --------------------------\n            with allure.step(f\"1. 取消订阅（账号：{account}）\"):\n                params = {\"id\": jeecg_rowkey}\n>               response = self.send_delete_request(\n                    logged_session,\n                    '/blockchain/master-slave/deletePa',\n                    params=params\n                )\n\ntest_cloudTrader\\test_add_delete.py:120: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <template.test_cloudTrader.test_add_delete.Test_delete_batch object at 0x000001D22C6B1850>\nlogged_session = <template.commons.session.EnvironmentSession object at 0x000001D22C6C44C0>\nurl = '/blockchain/master-slave/deletePa', json_data = None\nparams = {'id': '1978749551737966594'}, sleep_seconds = 3\n\n    def send_delete_request(self, logged_session, url, json_data=None, params=None, sleep_seconds=SLEEP_SECONDS):\n        \"\"\"\n        发送DELETE请求（异常分层优化）\n    \n        :param logged_session: 已登录的会话对象\n        :param url: 请求URL\n        :param json_data: 请求体JSON数据（可选）\n        :param params: URL查询参数（可选，如{'id': '1971039114011594754'}）\n        :param sleep_seconds: 请求后等待秒数\n        :return: 响应对象\n        \"\"\"\n        method = \"DELETE\"\n        with allure.step(f\"执行 {method} 请求: {url}\"):\n            try:\n                # 处理参数，确保查询参数通过params传递而非直接拼接在url中\n                full_url = url\n                if params:\n                    # 移除URL中已存在的查询参数，避免重复\n                    parsed_url = urlparse(url)\n                    if parsed_url.query:\n                        logger.warning(f\"URL中已包含查询参数: {parsed_url.query}，将被params参数覆盖\")\n                        full_url = urlunparse(parsed_url._replace(query=''))\n    \n                # 附加请求详情到allure报告\n                self._attach_request_details(\n                    method=method,\n                    url=full_url,\n                    headers=logged_session.headers,\n                    params=params,\n                    body=json_data,\n                    is_json=True,\n                )\n    \n                # 发送DELETE请求，查询参数通过params参数传递\n                response = logged_session.delete(\n                    full_url,\n                    json=json_data,\n                    params=params\n                )\n    \n                # 记录请求日志\n                logger.info(\n                    f\"[{self._get_current_time()}] {method}请求: {full_url} \"\n                    f\"| 参数: {params} | 数据: {json_data} | 状态码: {response.status_code}\"\n                )\n    \n                # 附加响应详情到allure报告\n                self._attach_response_details(response)\n    \n                # 请求后等待\n                if sleep_seconds > 0:\n                    time.sleep(sleep_seconds)\n    \n                return response\n    \n            except (SSLError, ConnectionError, Timeout) as e:\n                error_type = \"网络层异常\"\n                with allure.step(f\"{method} 请求{error_type}\"):\n                    self._attach_request_details(\n                        method=method,\n                        url=url,\n                        headers=logged_session.headers,\n                        params=params,\n                        body=json_data,\n                        is_json=True,\n                    )\n                    error_detail = (\n                        f\"{error_type}: {str(e)}\\n\"\n                        f\"URL: {url}\\n\"\n                        f\"查询参数: {params}\\n\"\n                        f\"请求头: {logged_session.headers}\\n\"\n                        f\"请求体: {json_data}\"\n                    )\n                    allure.attach(error_detail, f\"{error_type}详情\", allure.attachment_type.TEXT)\n                logger.error(\n                    f\"[{self._get_current_time()}] {method}请求{error_type}: {str(e)} \"\n                    f\"| URL: {url} | 参数: {params}\",\n                    exc_info=True\n                )\n>               raise ConnectionError(f\"Failed: {method}请求{error_type}（{str(e)[:1000]}）\") from e\nE               requests.exceptions.ConnectionError: Failed: DELETE请求网络层异常（HTTPSConnectionPool(host='dev.lgcopytrade.top', port=443): Max retries exceeded with url: /api/blockchain/master-slave/deletePa?id=1978749551737966594 (Caused by ProxyError('Unable to connect to proxy', FileNotFoundError(2, 'No such file or directory')))）\n\ncommons\\api_base.py:381: ConnectionError\n\nDuring handling of the above exception, another exception occurred:\n\nself = <template.test_cloudTrader.test_add_delete.Test_delete_batch object at 0x000001D22C6B1850>\naccount_info = {'account': '301392107', 'jeecg_rowkey': '1978745428095406081', 'pass_id': '1978745394211811330'}\nvar_manager = <template.commons.variable_manager.VariableManager object at 0x000001D22C6C4BE0>\nlogged_session = <template.commons.session.EnvironmentSession object at 0x000001D22C6C44C0>\ndb_transaction = <pymysql.connections.Connection object at 0x000001D22DDC7A00>\n\n    @allure.title(\"多账号批量解绑：取消订阅 + 前端解绑 + 数据库校验\")\n    @pytest.mark.parametrize(\"account_info\", get_follow_accounts_from_runtime_json())\n    def test_batch_unbind(self, account_info, var_manager, logged_session, db_transaction):\n        \"\"\"单个账号完整解绑流程：取消订阅→前端解绑→数据库校验\"\"\"\n        # 1. 执行阶段实时读取最新数据（关键步骤）\n        latest_accounts = get_follow_accounts_from_runtime_json()\n        current_account = account_info[\"account\"]\n    \n        # 2. 从最新数据中匹配当前账号\n        latest_info = next(\n            (item for item in latest_accounts if item[\"account\"] == current_account),\n            None\n        )\n        if not latest_info:\n            pytest.fail(f\"当前账号 {current_account} 在最新JSON中未找到\")\n    \n        # 3. 强制使用最新数据（覆盖参数化的旧数据）\n        account = latest_info[\"account\"]\n        pass_id = latest_info[\"pass_id\"]\n        jeecg_rowkey = latest_info[\"jeecg_rowkey\"]\n    \n        # 打印数据对比日志（用于调试新旧数据差异）\n        logging.info(f\"\\n[数据对比] 账号：{account}\"\n                     f\"\\n- 执行阶段最新jeecg_rowkey：{jeecg_rowkey}\"\n                     f\"\\n- 参数化阶段旧jeecg_rowkey：{account_info['jeecg_rowkey']}\")\n    \n        allure.dynamic.description(f\"当前解绑账号：{account}（pass_id：{pass_id}）\")\n    \n        try:\n            # -------------------------- 步骤1：取消订阅（使用最新jeecg_rowkey） --------------------------\n            with allure.step(f\"1. 取消订阅（账号：{account}）\"):\n                params = {\"id\": jeecg_rowkey}\n                response = self.send_delete_request(\n                    logged_session,\n                    '/blockchain/master-slave/deletePa',\n                    params=params\n                )\n    \n                self.assert_json_value(\n                    response,\n                    \"$.success\",\n                    True,\n                    f\"账号[{account}]取消订阅失败，响应：{response.text[:500]}\"\n                )\n                allure.attach(str(params), f\"{account}取消订阅参数\", allure.attachment_type.TEXT)\n                allure.attach(response.text, f\"{account}取消订阅响应\", allure.attachment_type.JSON)\n    \n            # -------------------------- 步骤2：前端-跟单账号解绑（使用最新pass_id） --------------------------\n            with allure.step(f\"2. 前端解绑跟单账号（账号：{account}）\"):\n                token_top = var_manager.get_variable(\"token_top\")\n                assert token_top, \"未获取到前端token（token_top）\"\n    \n                URL_TOP = var_manager.get_variable(\"URL_TOP\")\n                Host = var_manager.get_variable(\"Hosttop\")\n                url = f\"{URL_TOP}/blockchain/account/unbind?traderId={pass_id}\"\n                payload = json.dumps({})\n                headers = {\n                    'priority': 'u=1, i',\n                    'x-access-token': token_top,\n                    'User-Agent': 'Apifox/1.0.0 (https://apifox.com)',\n                    'content-type': 'application/json',\n                    'Accept': '*/*',\n                    'Host': Host,\n                    'Connection': 'keep-alive'\n                }\n    \n                response = requests.request(\"POST\", url, headers=headers, data=payload)\n                self.assert_json_value(\n                    response,\n                    \"$.success\",\n                    True,\n                    f\"账号[{account}]前端解绑失败，响应：{response.text[:500]}\"\n                )\n                allure.attach(url, f\"{account}解绑URL\", allure.attachment_type.TEXT)\n                allure.attach(json.dumps(headers), f\"{account}解绑请求头\", allure.attachment_type.JSON)\n                allure.attach(response.text, f\"{account}解绑响应\", allure.attachment_type.JSON)\n    \n            # -------------------------- 步骤3：数据库校验-账号状态为UNBIND --------------------------\n            with allure.step(f\"3. 数据库校验（账号：{account}）\"):\n                sql = \"\"\"\n                    SELECT status\n                    FROM bchain_trader\n                    WHERE id = %s\n                \"\"\"\n                db_data = self.query_database(\n                    db_transaction=db_transaction,\n                    sql=sql,\n                    params=(pass_id,)\n                )\n    \n                assert len(db_data) > 0, f\"数据库未查询到账号[{account}]（pass_id：{pass_id}）\"\n                actual_status = db_data[0][\"status\"]\n                assert actual_status == \"UNBIND\", \\\n                    f\"账号[{account}]解绑状态异常：实际={actual_status}，期望=UNBIND\"\n    \n                logging.info(f\"账号[{account}]解绑完成，数据库状态校验通过\")\n    \n        except Exception as e:\n            error_msg = f\"账号[{account}]解绑失败：{str(e)[:500]}\"\n            logging.error(error_msg, exc_info=True)\n            allure.attach(error_msg, f\"{account}解绑失败详情\", allure.attachment_type.TEXT)\n>           pytest.fail(error_msg)\nE           Failed: 账号[301392107]解绑失败：Failed: DELETE请求网络层异常（HTTPSConnectionPool(host='dev.lgcopytrade.top', port=443): Max retries exceeded with url: /api/blockchain/master-slave/deletePa?id=1978749551737966594 (Caused by ProxyError('Unable to connect to proxy', FileNotFoundError(2, 'No such file or directory')))）\n\ntest_cloudTrader\\test_add_delete.py:189: Failed",
    "steps" : [ {
      "name" : "1. 取消订阅（账号：301392107）",
      "time" : {
        "start" : 1760605837540,
        "stop" : 1760605837586,
        "duration" : 46
      },
      "status" : "broken",
      "statusMessage" : "requests.exceptions.ConnectionError: Failed: DELETE请求网络层异常（HTTPSConnectionPool(host='dev.lgcopytrade.top', port=443): Max retries exceeded with url: /api/blockchain/master-slave/deletePa?id=1978749551737966594 (Caused by ProxyError('Unable to connect to proxy', FileNotFoundError(2, 'No such file or directory')))）\n",
      "statusTrace" : "  File \"D:\\pycharm_test\\template\\test_cloudTrader\\test_add_delete.py\", line 120, in test_batch_unbind\n    response = self.send_delete_request(\n  File \"D:\\pycharm_test\\template\\commons\\api_base.py\", line 381, in send_delete_request\n    raise ConnectionError(f\"Failed: {method}请求{error_type}（{str(e)[:1000]}）\") from e\n",
      "steps" : [ {
        "name" : "执行 DELETE 请求: /blockchain/master-slave/deletePa",
        "time" : {
          "start" : 1760605837541,
          "stop" : 1760605837584,
          "duration" : 43
        },
        "status" : "broken",
        "statusMessage" : "requests.exceptions.ConnectionError: Failed: DELETE请求网络层异常（HTTPSConnectionPool(host='dev.lgcopytrade.top', port=443): Max retries exceeded with url: /api/blockchain/master-slave/deletePa?id=1978749551737966594 (Caused by ProxyError('Unable to connect to proxy', FileNotFoundError(2, 'No such file or directory')))）\n",
        "statusTrace" : "  File \"D:\\pycharm_test\\template\\commons\\api_base.py\", line 381, in send_delete_request\n    raise ConnectionError(f\"Failed: {method}请求{error_type}（{str(e)[:1000]}）\") from e\n",
        "steps" : [ {
          "name" : "请求详情",
          "time" : {
            "start" : 1760605837541,
            "stop" : 1760605837543,
            "duration" : 2
          },
          "status" : "passed",
          "steps" : [ ],
          "attachments" : [ {
            "uid" : "75fc6123de700a5d",
            "name" : "请求完整URL（含参数）",
            "source" : "75fc6123de700a5d.txt",
            "type" : "text/plain",
            "size" : 56
          }, {
            "uid" : "e39d54a86a7d6a6d",
            "name" : "URL查询参数",
            "source" : "e39d54a86a7d6a6d.json",
            "type" : "application/json",
            "size" : 33
          }, {
            "uid" : "c77f2a11d47b10c9",
            "name" : "请求头",
            "source" : "c77f2a11d47b10c9.json",
            "type" : "application/json",
            "size" : 429
          } ],
          "parameters" : [ ],
          "hasContent" : true,
          "stepsCount" : 0,
          "attachmentsCount" : 3,
          "shouldDisplayMessage" : false
        }, {
          "name" : "DELETE 请求网络层异常",
          "time" : {
            "start" : 1760605837579,
            "stop" : 1760605837583,
            "duration" : 4
          },
          "status" : "passed",
          "steps" : [ {
            "name" : "请求详情",
            "time" : {
              "start" : 1760605837579,
              "stop" : 1760605837582,
              "duration" : 3
            },
            "status" : "passed",
            "steps" : [ ],
            "attachments" : [ {
              "uid" : "f049f8bd53918565",
              "name" : "请求完整URL（含参数）",
              "source" : "f049f8bd53918565.txt",
              "type" : "text/plain",
              "size" : 56
            }, {
              "uid" : "ed2660e0e3239dca",
              "name" : "URL查询参数",
              "source" : "ed2660e0e3239dca.json",
              "type" : "application/json",
              "size" : 33
            }, {
              "uid" : "cfb3432a0a76ffb",
              "name" : "请求头",
              "source" : "cfb3432a0a76ffb.json",
              "type" : "application/json",
              "size" : 429
            } ],
            "parameters" : [ ],
            "hasContent" : true,
            "stepsCount" : 0,
            "attachmentsCount" : 3,
            "shouldDisplayMessage" : false
          } ],
          "attachments" : [ {
            "uid" : "5277ef00a10de9a3",
            "name" : "网络层异常详情",
            "source" : "5277ef00a10de9a3.txt",
            "type" : "text/plain",
            "size" : 791
          } ],
          "parameters" : [ ],
          "hasContent" : true,
          "stepsCount" : 1,
          "attachmentsCount" : 4,
          "shouldDisplayMessage" : false
        } ],
        "attachments" : [ ],
        "parameters" : [ ],
        "hasContent" : true,
        "stepsCount" : 3,
        "attachmentsCount" : 7,
        "shouldDisplayMessage" : true
      } ],
      "attachments" : [ ],
      "parameters" : [ ],
      "hasContent" : true,
      "stepsCount" : 4,
      "attachmentsCount" : 7,
      "shouldDisplayMessage" : false
    } ],
    "attachments" : [ {
      "uid" : "7188737e70b966d0",
      "name" : "301392107解绑失败详情",
      "source" : "7188737e70b966d0.txt",
      "type" : "text/plain",
      "size" : 327
    }, {
      "uid" : "e662f8499cc3c019",
      "name" : "log",
      "source" : "e662f8499cc3c019.txt",
      "type" : "text/plain",
      "size" : 25834
    } ],
    "parameters" : [ ],
    "hasContent" : true,
    "stepsCount" : 5,
    "attachmentsCount" : 9,
    "shouldDisplayMessage" : true
  },
  "afterStages" : [ {
    "name" : "db::0",
    "time" : {
      "start" : 1760605837784,
      "stop" : 1760605837785,
      "duration" : 1
    },
    "status" : "passed",
    "steps" : [ ],
    "attachments" : [ ],
    "parameters" : [ ],
    "hasContent" : false,
    "stepsCount" : 0,
    "attachmentsCount" : 0,
    "shouldDisplayMessage" : false
  }, {
    "name" : "db_transaction::0",
    "time" : {
      "start" : 1760605837783,
      "stop" : 1760605837783,
      "duration" : 0
    },
    "status" : "passed",
    "steps" : [ ],
    "attachments" : [ ],
    "parameters" : [ ],
    "hasContent" : false,
    "stepsCount" : 0,
    "attachmentsCount" : 0,
    "shouldDisplayMessage" : false
  } ],
  "labels" : [ {
    "name" : "feature",
    "value" : "账号管理-批量解绑跟随者账号"
  }, {
    "name" : "parentSuite",
    "value" : "test_cloudTrader"
  }, {
    "name" : "suite",
    "value" : "test_add_delete"
  }, {
    "name" : "subSuite",
    "value" : "Test_delete_batch"
  }, {
    "name" : "host",
    "value" : "DESKTOP-4S9CU1E"
  }, {
    "name" : "thread",
    "value" : "67168-MainThread"
  }, {
    "name" : "framework",
    "value" : "pytest"
  }, {
    "name" : "language",
    "value" : "cpython3"
  }, {
    "name" : "package",
    "value" : "test_cloudTrader.test_add_delete"
  }, {
    "name" : "resultFormat",
    "value" : "allure2"
  } ],
  "parameters" : [ {
    "name" : "account_info",
    "value" : "{'account': '301392107', 'pass_id': '1978745394211811330', 'jeecg_rowkey': '1978745428095406081'}"
  } ],
  "links" : [ ],
  "hidden" : false,
  "retry" : false,
  "extra" : {
    "severity" : "normal",
    "retries" : [ {
      "uid" : "550e89df6392e6b7",
      "status" : "failed",
      "statusDetails" : "Failed: 账号[301392107]解绑失败：Failed: DELETE请求网络层异常（HTTPSConnectionPool(host='dev.lgcopytrade.top', port=443): Max retries exceeded with url: /api/blockchain/master-slave/deletePa?id=1978749551737966594 (Caused by ProxyError('Unable to connect to proxy', FileNotFoundError(2, 'No such file or directory')))）",
      "time" : {
        "start" : 1760605826851,
        "stop" : 1760605826900,
        "duration" : 49
      }
    }, {
      "uid" : "79885d7bfbf915dc",
      "status" : "failed",
      "statusDetails" : "Failed: 账号[301392107]解绑失败：Failed: DELETE请求网络层异常（HTTPSConnectionPool(host='dev.lgcopytrade.top', port=443): Max retries exceeded with url: /api/blockchain/master-slave/deletePa?id=1978749551737966594 (Caused by ProxyError('Unable to connect to proxy', FileNotFoundError(2, 'No such file or directory')))）",
      "time" : {
        "start" : 1760605816322,
        "stop" : 1760605816342,
        "duration" : 20
      }
    }, {
      "uid" : "4c60a9d568b6d56c",
      "status" : "failed",
      "statusDetails" : "Failed: 账号[301392107]解绑失败：Failed: DELETE请求网络层异常（HTTPSConnectionPool(host='dev.lgcopytrade.top', port=443): Max retries exceeded with url: /api/blockchain/master-slave/deletePa?id=1978749551737966594 (Caused by ProxyError('Unable to connect to proxy', FileNotFoundError(2, 'No such file or directory')))）",
      "time" : {
        "start" : 1760605805768,
        "stop" : 1760605805789,
        "duration" : 21
      }
    } ],
    "categories" : [ {
      "name" : "Product defects",
      "matchedStatuses" : [ ],
      "flaky" : false
    } ],
    "tags" : [ ]
  },
  "source" : "d608e91d4815d31f.json",
  "parameterValues" : [ "{'account': '301392107', 'pass_id': '1978745394211811330', 'jeecg_rowkey': '1978745428095406081'}" ]
}