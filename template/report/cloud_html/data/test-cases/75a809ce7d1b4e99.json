{
  "uid" : "75a809ce7d1b4e99",
  "name" : "跟单社区后台-账号管理-交易员账号-解绑账户",
  "fullName" : "test_cloudTrader.test_delete.Test_delete#test_account_unbindPa_trader",
  "historyId" : "3f3cb5035a95fdc284ff4e0134d01230",
  "time" : {
    "start" : 1760606119790,
    "stop" : 1760606119809,
    "duration" : 19
  },
  "status" : "broken",
  "statusMessage" : "requests.exceptions.ConnectionError: Failed: POST 请求异常（HTTPSConnectionPool(host='dev.lgcopytrade.top', port=443): Max retries exceeded with url: /api/blockchain/account/unbindPa?traderId=1978748962360750082 (Caused by ProxyError('Unable to connect to proxy', FileNotFoundError(2, 'No such file or directory')))）",
  "statusTrace" : "self = <urllib3.connectionpool.HTTPSConnectionPool object at 0x000001D22C9D3850>\nmethod = 'POST'\nurl = '/api/blockchain/account/unbindPa?traderId=1978748962360750082'\nbody = b'null'\nheaders = {'User-Agent': 'python-requests/2.32.4', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-aliv...nant_id': '0', 'Content-Type': 'application/json; charset=utf-8', 'Host': 'dev.lgcopytrade.top', 'Content-Length': '4'}\nretries = Retry(total=0, connect=None, read=False, redirect=None, status=None)\nredirect = False, assert_same_host = False\ntimeout = Timeout(connect=None, read=None, total=None), pool_timeout = None\nrelease_conn = False, chunked = False, body_pos = None, preload_content = False\ndecode_content = False, response_kw = {}\nparsed_url = Url(scheme=None, auth=None, host=None, port=None, path='/api/blockchain/account/unbindPa', query='traderId=1978748962360750082', fragment=None)\ndestination_scheme = None, conn = None, release_this_conn = True\nhttp_tunnel_required = True, err = None, clean_exit = False\n\n    def urlopen(  # type: ignore[override]\n        self,\n        method: str,\n        url: str,\n        body: _TYPE_BODY | None = None,\n        headers: typing.Mapping[str, str] | None = None,\n        retries: Retry | bool | int | None = None,\n        redirect: bool = True,\n        assert_same_host: bool = True,\n        timeout: _TYPE_TIMEOUT = _DEFAULT_TIMEOUT,\n        pool_timeout: int | None = None,\n        release_conn: bool | None = None,\n        chunked: bool = False,\n        body_pos: _TYPE_BODY_POSITION | None = None,\n        preload_content: bool = True,\n        decode_content: bool = True,\n        **response_kw: typing.Any,\n    ) -> BaseHTTPResponse:\n        \"\"\"\n        Get a connection from the pool and perform an HTTP request. This is the\n        lowest level call for making a request, so you'll need to specify all\n        the raw details.\n    \n        .. note::\n    \n           More commonly, it's appropriate to use a convenience method\n           such as :meth:`request`.\n    \n        .. note::\n    \n           `release_conn` will only behave as expected if\n           `preload_content=False` because we want to make\n           `preload_content=False` the default behaviour someday soon without\n           breaking backwards compatibility.\n    \n        :param method:\n            HTTP request method (such as GET, POST, PUT, etc.)\n    \n        :param url:\n            The URL to perform the request on.\n    \n        :param body:\n            Data to send in the request body, either :class:`str`, :class:`bytes`,\n            an iterable of :class:`str`/:class:`bytes`, or a file-like object.\n    \n        :param headers:\n            Dictionary of custom headers to send, such as User-Agent,\n            If-None-Match, etc. If None, pool headers are used. If provided,\n            these headers completely replace any pool-specific headers.\n    \n        :param retries:\n            Configure the number of retries to allow before raising a\n            :class:`~urllib3.exceptions.MaxRetryError` exception.\n    \n            If ``None`` (default) will retry 3 times, see ``Retry.DEFAULT``. Pass a\n            :class:`~urllib3.util.retry.Retry` object for fine-grained control\n            over different types of retries.\n            Pass an integer number to retry connection errors that many times,\n            but no other types of errors. Pass zero to never retry.\n    \n            If ``False``, then retries are disabled and any exception is raised\n            immediately. Also, instead of raising a MaxRetryError on redirects,\n            the redirect response will be returned.\n    \n        :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.\n    \n        :param redirect:\n            If True, automatically handle redirects (status codes 301, 302,\n            303, 307, 308). Each redirect counts as a retry. Disabling retries\n            will disable redirect, too.\n    \n        :param assert_same_host:\n            If ``True``, will make sure that the host of the pool requests is\n            consistent else will raise HostChangedError. When ``False``, you can\n            use the pool on an HTTP proxy and request foreign hosts.\n    \n        :param timeout:\n            If specified, overrides the default timeout for this one\n            request. It may be a float (in seconds) or an instance of\n            :class:`urllib3.util.Timeout`.\n    \n        :param pool_timeout:\n            If set and the pool is set to block=True, then this method will\n            block for ``pool_timeout`` seconds and raise EmptyPoolError if no\n            connection is available within the time period.\n    \n        :param bool preload_content:\n            If True, the response's body will be preloaded into memory.\n    \n        :param bool decode_content:\n            If True, will attempt to decode the body based on the\n            'content-encoding' header.\n    \n        :param release_conn:\n            If False, then the urlopen call will not release the connection\n            back into the pool once a response is received (but will release if\n            you read the entire contents of the response such as when\n            `preload_content=True`). This is useful if you're not preloading\n            the response's content immediately. You will need to call\n            ``r.release_conn()`` on the response ``r`` to return the connection\n            back into the pool. If None, it takes the value of ``preload_content``\n            which defaults to ``True``.\n    \n        :param bool chunked:\n            If True, urllib3 will send the body using chunked transfer\n            encoding. Otherwise, urllib3 will send the body using the standard\n            content-length form. Defaults to False.\n    \n        :param int body_pos:\n            Position to seek to in file-like body in the event of a retry or\n            redirect. Typically this won't need to be set because urllib3 will\n            auto-populate the value when needed.\n        \"\"\"\n        parsed_url = parse_url(url)\n        destination_scheme = parsed_url.scheme\n    \n        if headers is None:\n            headers = self.headers\n    \n        if not isinstance(retries, Retry):\n            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)\n    \n        if release_conn is None:\n            release_conn = preload_content\n    \n        # Check host\n        if assert_same_host and not self.is_same_host(url):\n            raise HostChangedError(self, url, retries)\n    \n        # Ensure that the URL we're connecting to is properly encoded\n        if url.startswith(\"/\"):\n            url = to_str(_encode_target(url))\n        else:\n            url = to_str(parsed_url.url)\n    \n        conn = None\n    \n        # Track whether `conn` needs to be released before\n        # returning/raising/recursing. Update this variable if necessary, and\n        # leave `release_conn` constant throughout the function. That way, if\n        # the function recurses, the original value of `release_conn` will be\n        # passed down into the recursive call, and its value will be respected.\n        #\n        # See issue #651 [1] for details.\n        #\n        # [1] <https://github.com/urllib3/urllib3/issues/651>\n        release_this_conn = release_conn\n    \n        http_tunnel_required = connection_requires_http_tunnel(\n            self.proxy, self.proxy_config, destination_scheme\n        )\n    \n        # Merge the proxy headers. Only done when not using HTTP CONNECT. We\n        # have to copy the headers dict so we can safely change it without those\n        # changes being reflected in anyone else's copy.\n        if not http_tunnel_required:\n            headers = headers.copy()  # type: ignore[attr-defined]\n            headers.update(self.proxy_headers)  # type: ignore[union-attr]\n    \n        # Must keep the exception bound to a separate variable or else Python 3\n        # complains about UnboundLocalError.\n        err = None\n    \n        # Keep track of whether we cleanly exited the except block. This\n        # ensures we do proper cleanup in finally.\n        clean_exit = False\n    \n        # Rewind body position, if needed. Record current position\n        # for future rewinds in the event of a redirect/retry.\n        body_pos = set_file_position(body, body_pos)\n    \n        try:\n            # Request a connection from the queue.\n            timeout_obj = self._get_timeout(timeout)\n            conn = self._get_conn(timeout=pool_timeout)\n    \n            conn.timeout = timeout_obj.connect_timeout  # type: ignore[assignment]\n    \n            # Is this a closed/new connection that requires CONNECT tunnelling?\n            if self.proxy is not None and http_tunnel_required and conn.is_closed:\n                try:\n>                   self._prepare_proxy(conn)\n\n..\\Community\\lib\\site-packages\\urllib3\\connectionpool.py:775: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n..\\Community\\lib\\site-packages\\urllib3\\connectionpool.py:1044: in _prepare_proxy\n    conn.connect()\n..\\Community\\lib\\site-packages\\urllib3\\connection.py:702: in connect\n    self.sock = sock = self._connect_tls_proxy(self.host, sock)\n..\\Community\\lib\\site-packages\\urllib3\\connection.py:802: in _connect_tls_proxy\n    sock_and_verified = _ssl_wrap_socket_and_match_hostname(\n..\\Community\\lib\\site-packages\\urllib3\\connection.py:909: in _ssl_wrap_socket_and_match_hostname\n    ssl_sock = ssl_wrap_socket(\n..\\Community\\lib\\site-packages\\urllib3\\util\\ssl_.py:469: in ssl_wrap_socket\n    ssl_sock = _ssl_wrap_socket_impl(sock, context, tls_in_tls, server_hostname)\n..\\Community\\lib\\site-packages\\urllib3\\util\\ssl_.py:513: in _ssl_wrap_socket_impl\n    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)\nD:\\python_tools\\python\\lib\\ssl.py:500: in wrap_socket\n    return self.sslsocket_class._create(\nD:\\python_tools\\python\\lib\\ssl.py:1040: in _create\n    self.do_handshake()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <ssl.SSLSocket [closed] fd=-1, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0>\nblock = False\n\n    @_sslcopydoc\n    def do_handshake(self, block=False):\n        self._check_connected()\n        timeout = self.gettimeout()\n        try:\n            if timeout == 0.0 and block:\n                self.settimeout(None)\n>           self._sslobj.do_handshake()\nE           FileNotFoundError: [Errno 2] No such file or directory\n\nD:\\python_tools\\python\\lib\\ssl.py:1309: FileNotFoundError\n\nThe above exception was the direct cause of the following exception:\nTraceback (most recent call last):\n  File \"D:\\pycharm_test\\Community\\lib\\site-packages\\urllib3\\connectionpool.py\", line 775, in urlopen\n    self._prepare_proxy(conn)\n  File \"D:\\pycharm_test\\Community\\lib\\site-packages\\urllib3\\connectionpool.py\", line 1044, in _prepare_proxy\n    conn.connect()\n  File \"D:\\pycharm_test\\Community\\lib\\site-packages\\urllib3\\connection.py\", line 702, in connect\n    self.sock = sock = self._connect_tls_proxy(self.host, sock)\n  File \"D:\\pycharm_test\\Community\\lib\\site-packages\\urllib3\\connection.py\", line 802, in _connect_tls_proxy\n    sock_and_verified = _ssl_wrap_socket_and_match_hostname(\n  File \"D:\\pycharm_test\\Community\\lib\\site-packages\\urllib3\\connection.py\", line 909, in _ssl_wrap_socket_and_match_hostname\n    ssl_sock = ssl_wrap_socket(\n  File \"D:\\pycharm_test\\Community\\lib\\site-packages\\urllib3\\util\\ssl_.py\", line 469, in ssl_wrap_socket\n    ssl_sock = _ssl_wrap_socket_impl(sock, context, tls_in_tls, server_hostname)\n  File \"D:\\pycharm_test\\Community\\lib\\site-packages\\urllib3\\util\\ssl_.py\", line 513, in _ssl_wrap_socket_impl\n    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)\n  File \"D:\\python_tools\\python\\lib\\ssl.py\", line 500, in wrap_socket\n    return self.sslsocket_class._create(\n  File \"D:\\python_tools\\python\\lib\\ssl.py\", line 1040, in _create\n    self.do_handshake()\n  File \"D:\\python_tools\\python\\lib\\ssl.py\", line 1309, in do_handshake\n    self._sslobj.do_handshake()\nFileNotFoundError: [Errno 2] No such file or directory\n\nThe above exception was the direct cause of the following exception:\n\nurllib3.exceptions.ProxyError: ('Unable to connect to proxy', FileNotFoundError(2, 'No such file or directory'))\n\nThe above exception was the direct cause of the following exception:\n\nself = <requests.adapters.HTTPAdapter object at 0x000001D22C6C4E80>\nrequest = <PreparedRequest [POST]>, stream = False\ntimeout = Timeout(connect=None, read=None, total=None), verify = True\ncert = None\nproxies = OrderedDict([('http', 'http://127.0.0.1:10809'), ('https', 'https://127.0.0.1:10809'), ('ftp', 'ftp://127.0.0.1:10809')])\n\n    def send(\n        self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None\n    ):\n        \"\"\"Sends PreparedRequest object. Returns Response object.\n    \n        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\n        :param stream: (optional) Whether to stream the request content.\n        :param timeout: (optional) How long to wait for the server to send\n            data before giving up, as a float, or a :ref:`(connect timeout,\n            read timeout) <timeouts>` tuple.\n        :type timeout: float or tuple or urllib3 Timeout object\n        :param verify: (optional) Either a boolean, in which case it controls whether\n            we verify the server's TLS certificate, or a string, in which case it\n            must be a path to a CA bundle to use\n        :param cert: (optional) Any user-provided SSL certificate to be trusted.\n        :param proxies: (optional) The proxies dictionary to apply to the request.\n        :rtype: requests.Response\n        \"\"\"\n    \n        try:\n            conn = self.get_connection_with_tls_context(\n                request, verify, proxies=proxies, cert=cert\n            )\n        except LocationValueError as e:\n            raise InvalidURL(e, request=request)\n    \n        self.cert_verify(conn, request.url, verify, cert)\n        url = self.request_url(request, proxies)\n        self.add_headers(\n            request,\n            stream=stream,\n            timeout=timeout,\n            verify=verify,\n            cert=cert,\n            proxies=proxies,\n        )\n    \n        chunked = not (request.body is None or \"Content-Length\" in request.headers)\n    \n        if isinstance(timeout, tuple):\n            try:\n                connect, read = timeout\n                timeout = TimeoutSauce(connect=connect, read=read)\n            except ValueError:\n                raise ValueError(\n                    f\"Invalid timeout {timeout}. Pass a (connect, read) timeout tuple, \"\n                    f\"or a single float to set both timeouts to the same value.\"\n                )\n        elif isinstance(timeout, TimeoutSauce):\n            pass\n        else:\n            timeout = TimeoutSauce(connect=timeout, read=timeout)\n    \n        try:\n>           resp = conn.urlopen(\n                method=request.method,\n                url=url,\n                body=request.body,\n                headers=request.headers,\n                redirect=False,\n                assert_same_host=False,\n                preload_content=False,\n                decode_content=False,\n                retries=self.max_retries,\n                timeout=timeout,\n                chunked=chunked,\n            )\n\n..\\Community\\lib\\site-packages\\requests\\adapters.py:667: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n..\\Community\\lib\\site-packages\\urllib3\\connectionpool.py:843: in urlopen\n    retries = retries.increment(\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = Retry(total=0, connect=None, read=False, redirect=None, status=None)\nmethod = 'POST'\nurl = '/api/blockchain/account/unbindPa?traderId=1978748962360750082'\nresponse = None\nerror = ProxyError('Unable to connect to proxy', FileNotFoundError(2, 'No such file or directory'))\n_pool = <urllib3.connectionpool.HTTPSConnectionPool object at 0x000001D22C9D3850>\n_stacktrace = <traceback object at 0x000001D22E4E1040>\n\n    def increment(\n        self,\n        method: str | None = None,\n        url: str | None = None,\n        response: BaseHTTPResponse | None = None,\n        error: Exception | None = None,\n        _pool: ConnectionPool | None = None,\n        _stacktrace: TracebackType | None = None,\n    ) -> Self:\n        \"\"\"Return a new Retry object with incremented retry counters.\n    \n        :param response: A response object, or None, if the server did not\n            return a response.\n        :type response: :class:`~urllib3.response.BaseHTTPResponse`\n        :param Exception error: An error encountered during the request, or\n            None if the response was received successfully.\n    \n        :return: A new ``Retry`` object.\n        \"\"\"\n        if self.total is False and error:\n            # Disabled, indicate to re-raise the error.\n            raise reraise(type(error), error, _stacktrace)\n    \n        total = self.total\n        if total is not None:\n            total -= 1\n    \n        connect = self.connect\n        read = self.read\n        redirect = self.redirect\n        status_count = self.status\n        other = self.other\n        cause = \"unknown\"\n        status = None\n        redirect_location = None\n    \n        if error and self._is_connection_error(error):\n            # Connect retry?\n            if connect is False:\n                raise reraise(type(error), error, _stacktrace)\n            elif connect is not None:\n                connect -= 1\n    \n        elif error and self._is_read_error(error):\n            # Read retry?\n            if read is False or method is None or not self._is_method_retryable(method):\n                raise reraise(type(error), error, _stacktrace)\n            elif read is not None:\n                read -= 1\n    \n        elif error:\n            # Other retry?\n            if other is not None:\n                other -= 1\n    \n        elif response and response.get_redirect_location():\n            # Redirect retry?\n            if redirect is not None:\n                redirect -= 1\n            cause = \"too many redirects\"\n            response_redirect_location = response.get_redirect_location()\n            if response_redirect_location:\n                redirect_location = response_redirect_location\n            status = response.status\n    \n        else:\n            # Incrementing because of a server error like a 500 in\n            # status_forcelist and the given method is in the allowed_methods\n            cause = ResponseError.GENERIC_ERROR\n            if response and response.status:\n                if status_count is not None:\n                    status_count -= 1\n                cause = ResponseError.SPECIFIC_ERROR.format(status_code=response.status)\n                status = response.status\n    \n        history = self.history + (\n            RequestHistory(method, url, error, status, redirect_location),\n        )\n    \n        new_retry = self.new(\n            total=total,\n            connect=connect,\n            read=read,\n            redirect=redirect,\n            status=status_count,\n            other=other,\n            history=history,\n        )\n    \n        if new_retry.is_exhausted():\n            reason = error or ResponseError(cause)\n>           raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\nE           urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='dev.lgcopytrade.top', port=443): Max retries exceeded with url: /api/blockchain/account/unbindPa?traderId=1978748962360750082 (Caused by ProxyError('Unable to connect to proxy', FileNotFoundError(2, 'No such file or directory')))\n\n..\\Community\\lib\\site-packages\\urllib3\\util\\retry.py:519: MaxRetryError\n\nDuring handling of the above exception, another exception occurred:\n\nself = <template.test_cloudTrader.test_delete.Test_delete object at 0x000001D22C6BDFD0>\nlogged_session = <template.commons.session.EnvironmentSession object at 0x000001D22C6C44C0>\nurl = '/blockchain/account/unbindPa', json_data = None, data = None\nfiles = None, params = {'traderId': '1978748962360750082'}, sleep_seconds = 3\n\n    def send_post_request(self, logged_session, url, json_data=None, data=None, files=None,\n                          params=None,  # 新增：支持URL查询参数\n                          sleep_seconds=SLEEP_SECONDS):\n        \"\"\"发送POST请求（异常分层优化，新增params参数支持URL查询）\"\"\"\n        method = \"POST\"\n        with allure.step(f\"执行 {method} 请求\"):\n            try:\n                # 1. 附加请求详情到Allure（新增params展示）\n                self._attach_request_details(\n                    method=method,\n                    url=url,\n                    headers=logged_session.headers,\n                    params=params,  # 新增：将params传入，用于Allure展示\n                    body=json_data if json_data else data,\n                    is_json=bool(json_data),\n                )\n    \n                # 2. 发送POST请求（根据不同场景携带params）\n                if files:\n                    # 场景1：带文件上传（表单数据+URL参数）\n                    response = logged_session.post(\n                        url=url,\n                        data=data,\n                        files=files,\n                        params=params  # 新增：传递URL参数\n                    )\n                    logger.info(\n                        f\"[{self._get_current_time()}] POST请求（带文件+URL参数）: {url} \"\n                        f\"| URL参数: {params} | 表单数据: {data}\"\n                    )\n                elif json_data:\n                    # 场景2：JSON请求体（JSON数据+URL参数）\n                    response = logged_session.post(\n                        url=url,\n                        json=json_data,\n                        params=params  # 新增：传递URL参数\n                    )\n                    logger.info(\n                        f\"[{self._get_current_time()}] POST请求（JSON+URL参数）: {url} \"\n                        f\"| URL参数: {params} | JSON数据: {json_data}\"\n                    )\n                else:\n                    # 场景3：普通表单请求（表单数据+URL参数）\n>                   response = logged_session.post(\n                        url=url,\n                        data=data,\n                        params=params  # 新增：传递URL参数\n                    )\n\ncommons\\api_base.py:215: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n..\\Community\\lib\\site-packages\\requests\\sessions.py:637: in post\n    return self.request(\"POST\", url, data=data, json=json, **kwargs)\ncommons\\session.py:135: in request\n    response = super().request(method, full_url, *args, **kwargs)\n..\\Community\\lib\\site-packages\\requests\\sessions.py:589: in request\n    resp = self.send(prep, **send_kwargs)\n..\\Community\\lib\\site-packages\\requests\\sessions.py:703: in send\n    r = adapter.send(request, **kwargs)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <requests.adapters.HTTPAdapter object at 0x000001D22C6C4E80>\nrequest = <PreparedRequest [POST]>, stream = False\ntimeout = Timeout(connect=None, read=None, total=None), verify = True\ncert = None\nproxies = OrderedDict([('http', 'http://127.0.0.1:10809'), ('https', 'https://127.0.0.1:10809'), ('ftp', 'ftp://127.0.0.1:10809')])\n\n    def send(\n        self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None\n    ):\n        \"\"\"Sends PreparedRequest object. Returns Response object.\n    \n        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\n        :param stream: (optional) Whether to stream the request content.\n        :param timeout: (optional) How long to wait for the server to send\n            data before giving up, as a float, or a :ref:`(connect timeout,\n            read timeout) <timeouts>` tuple.\n        :type timeout: float or tuple or urllib3 Timeout object\n        :param verify: (optional) Either a boolean, in which case it controls whether\n            we verify the server's TLS certificate, or a string, in which case it\n            must be a path to a CA bundle to use\n        :param cert: (optional) Any user-provided SSL certificate to be trusted.\n        :param proxies: (optional) The proxies dictionary to apply to the request.\n        :rtype: requests.Response\n        \"\"\"\n    \n        try:\n            conn = self.get_connection_with_tls_context(\n                request, verify, proxies=proxies, cert=cert\n            )\n        except LocationValueError as e:\n            raise InvalidURL(e, request=request)\n    \n        self.cert_verify(conn, request.url, verify, cert)\n        url = self.request_url(request, proxies)\n        self.add_headers(\n            request,\n            stream=stream,\n            timeout=timeout,\n            verify=verify,\n            cert=cert,\n            proxies=proxies,\n        )\n    \n        chunked = not (request.body is None or \"Content-Length\" in request.headers)\n    \n        if isinstance(timeout, tuple):\n            try:\n                connect, read = timeout\n                timeout = TimeoutSauce(connect=connect, read=read)\n            except ValueError:\n                raise ValueError(\n                    f\"Invalid timeout {timeout}. Pass a (connect, read) timeout tuple, \"\n                    f\"or a single float to set both timeouts to the same value.\"\n                )\n        elif isinstance(timeout, TimeoutSauce):\n            pass\n        else:\n            timeout = TimeoutSauce(connect=timeout, read=timeout)\n    \n        try:\n            resp = conn.urlopen(\n                method=request.method,\n                url=url,\n                body=request.body,\n                headers=request.headers,\n                redirect=False,\n                assert_same_host=False,\n                preload_content=False,\n                decode_content=False,\n                retries=self.max_retries,\n                timeout=timeout,\n                chunked=chunked,\n            )\n    \n        except (ProtocolError, OSError) as err:\n            raise ConnectionError(err, request=request)\n    \n        except MaxRetryError as e:\n            if isinstance(e.reason, ConnectTimeoutError):\n                # TODO: Remove this in 3.0.0: see #2811\n                if not isinstance(e.reason, NewConnectionError):\n                    raise ConnectTimeout(e, request=request)\n    \n            if isinstance(e.reason, ResponseError):\n                raise RetryError(e, request=request)\n    \n            if isinstance(e.reason, _ProxyError):\n>               raise ProxyError(e, request=request)\nE               requests.exceptions.ProxyError: HTTPSConnectionPool(host='dev.lgcopytrade.top', port=443): Max retries exceeded with url: /api/blockchain/account/unbindPa?traderId=1978748962360750082 (Caused by ProxyError('Unable to connect to proxy', FileNotFoundError(2, 'No such file or directory')))\n\n..\\Community\\lib\\site-packages\\requests\\adapters.py:694: ProxyError\n\nThe above exception was the direct cause of the following exception:\n\nself = <template.test_cloudTrader.test_delete.Test_delete object at 0x000001D22C6BDFD0>\nvar_manager = <template.commons.variable_manager.VariableManager object at 0x000001D22C6C4BE0>\nlogged_session = <template.commons.session.EnvironmentSession object at 0x000001D22C6C44C0>\n\n>   ???\n\nD:\\pycharm_test\\template\\test_community\\test_delete.py:247: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <template.test_cloudTrader.test_delete.Test_delete object at 0x000001D22C6BDFD0>\nlogged_session = <template.commons.session.EnvironmentSession object at 0x000001D22C6C44C0>\nurl = '/blockchain/account/unbindPa', json_data = None, data = None\nfiles = None, params = {'traderId': '1978748962360750082'}, sleep_seconds = 3\n\n    def send_post_request(self, logged_session, url, json_data=None, data=None, files=None,\n                          params=None,  # 新增：支持URL查询参数\n                          sleep_seconds=SLEEP_SECONDS):\n        \"\"\"发送POST请求（异常分层优化，新增params参数支持URL查询）\"\"\"\n        method = \"POST\"\n        with allure.step(f\"执行 {method} 请求\"):\n            try:\n                # 1. 附加请求详情到Allure（新增params展示）\n                self._attach_request_details(\n                    method=method,\n                    url=url,\n                    headers=logged_session.headers,\n                    params=params,  # 新增：将params传入，用于Allure展示\n                    body=json_data if json_data else data,\n                    is_json=bool(json_data),\n                )\n    \n                # 2. 发送POST请求（根据不同场景携带params）\n                if files:\n                    # 场景1：带文件上传（表单数据+URL参数）\n                    response = logged_session.post(\n                        url=url,\n                        data=data,\n                        files=files,\n                        params=params  # 新增：传递URL参数\n                    )\n                    logger.info(\n                        f\"[{self._get_current_time()}] POST请求（带文件+URL参数）: {url} \"\n                        f\"| URL参数: {params} | 表单数据: {data}\"\n                    )\n                elif json_data:\n                    # 场景2：JSON请求体（JSON数据+URL参数）\n                    response = logged_session.post(\n                        url=url,\n                        json=json_data,\n                        params=params  # 新增：传递URL参数\n                    )\n                    logger.info(\n                        f\"[{self._get_current_time()}] POST请求（JSON+URL参数）: {url} \"\n                        f\"| URL参数: {params} | JSON数据: {json_data}\"\n                    )\n                else:\n                    # 场景3：普通表单请求（表单数据+URL参数）\n                    response = logged_session.post(\n                        url=url,\n                        data=data,\n                        params=params  # 新增：传递URL参数\n                    )\n                    logger.info(\n                        f\"[{self._get_current_time()}] POST请求（表单+URL参数）: {url} \"\n                        f\"| URL参数: {params} | 表单数据: {data}\"\n                    )\n    \n                # 3. 附加响应详情（原有逻辑不变）\n                self._attach_response_details(response)\n    \n                # 4. 请求后等待（原有逻辑不变）\n                if sleep_seconds > 0:\n                    logger.info(f\"[{self._get_current_time()}] 请求后等待 {sleep_seconds} 秒\")\n                    time.sleep(sleep_seconds)\n    \n                return response\n    \n            # 5. 异常捕获与处理（新增params到异常详情）\n            except (SSLError, ConnectionError, Timeout, RequestException) as e:\n                with allure.step(f\"{method} 请求异常\"):\n                    self._attach_request_details(\n                        method=method,\n                        url=url,\n                        headers=logged_session.headers,\n                        params=params,  # 新增：异常时也展示URL参数\n                        body=json_data if json_data else data,\n                        is_json=bool(json_data),\n                    )\n                    error_detail = (\n                        f\"请求异常: {str(e)}\\n\"\n                        f\"URL: {url}\\n\"\n                        f\"URL参数: {params}\\n\"  # 新增：异常详情中显示URL参数\n                        f\"请求头: {logged_session.headers}\\n\"\n                        f\"请求体: {json_data if json_data else data}\"\n                    )\n                    allure.attach(error_detail, \"请求异常详情\", allure.attachment_type.TEXT)\n                logger.error(\n                    f\"[{self._get_current_time()}] {method} 请求异常: {str(e)} \"\n                    f\"| URL: {url} | URL参数: {params}\",  # 新增：日志中打印URL参数\n                    exc_info=True\n                )\n>               raise ConnectionError(f\"Failed: {method} 请求异常（{str(e)[:1000]}）\") from e\nE               requests.exceptions.ConnectionError: Failed: POST 请求异常（HTTPSConnectionPool(host='dev.lgcopytrade.top', port=443): Max retries exceeded with url: /api/blockchain/account/unbindPa?traderId=1978748962360750082 (Caused by ProxyError('Unable to connect to proxy', FileNotFoundError(2, 'No such file or directory')))）\n\ncommons\\api_base.py:259: ConnectionError",
  "flaky" : false,
  "newFailed" : false,
  "beforeStages" : [ ],
  "testStage" : {
    "status" : "broken",
    "statusMessage" : "requests.exceptions.ConnectionError: Failed: POST 请求异常（HTTPSConnectionPool(host='dev.lgcopytrade.top', port=443): Max retries exceeded with url: /api/blockchain/account/unbindPa?traderId=1978748962360750082 (Caused by ProxyError('Unable to connect to proxy', FileNotFoundError(2, 'No such file or directory')))）",
    "statusTrace" : "self = <urllib3.connectionpool.HTTPSConnectionPool object at 0x000001D22C9D3850>\nmethod = 'POST'\nurl = '/api/blockchain/account/unbindPa?traderId=1978748962360750082'\nbody = b'null'\nheaders = {'User-Agent': 'python-requests/2.32.4', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-aliv...nant_id': '0', 'Content-Type': 'application/json; charset=utf-8', 'Host': 'dev.lgcopytrade.top', 'Content-Length': '4'}\nretries = Retry(total=0, connect=None, read=False, redirect=None, status=None)\nredirect = False, assert_same_host = False\ntimeout = Timeout(connect=None, read=None, total=None), pool_timeout = None\nrelease_conn = False, chunked = False, body_pos = None, preload_content = False\ndecode_content = False, response_kw = {}\nparsed_url = Url(scheme=None, auth=None, host=None, port=None, path='/api/blockchain/account/unbindPa', query='traderId=1978748962360750082', fragment=None)\ndestination_scheme = None, conn = None, release_this_conn = True\nhttp_tunnel_required = True, err = None, clean_exit = False\n\n    def urlopen(  # type: ignore[override]\n        self,\n        method: str,\n        url: str,\n        body: _TYPE_BODY | None = None,\n        headers: typing.Mapping[str, str] | None = None,\n        retries: Retry | bool | int | None = None,\n        redirect: bool = True,\n        assert_same_host: bool = True,\n        timeout: _TYPE_TIMEOUT = _DEFAULT_TIMEOUT,\n        pool_timeout: int | None = None,\n        release_conn: bool | None = None,\n        chunked: bool = False,\n        body_pos: _TYPE_BODY_POSITION | None = None,\n        preload_content: bool = True,\n        decode_content: bool = True,\n        **response_kw: typing.Any,\n    ) -> BaseHTTPResponse:\n        \"\"\"\n        Get a connection from the pool and perform an HTTP request. This is the\n        lowest level call for making a request, so you'll need to specify all\n        the raw details.\n    \n        .. note::\n    \n           More commonly, it's appropriate to use a convenience method\n           such as :meth:`request`.\n    \n        .. note::\n    \n           `release_conn` will only behave as expected if\n           `preload_content=False` because we want to make\n           `preload_content=False` the default behaviour someday soon without\n           breaking backwards compatibility.\n    \n        :param method:\n            HTTP request method (such as GET, POST, PUT, etc.)\n    \n        :param url:\n            The URL to perform the request on.\n    \n        :param body:\n            Data to send in the request body, either :class:`str`, :class:`bytes`,\n            an iterable of :class:`str`/:class:`bytes`, or a file-like object.\n    \n        :param headers:\n            Dictionary of custom headers to send, such as User-Agent,\n            If-None-Match, etc. If None, pool headers are used. If provided,\n            these headers completely replace any pool-specific headers.\n    \n        :param retries:\n            Configure the number of retries to allow before raising a\n            :class:`~urllib3.exceptions.MaxRetryError` exception.\n    \n            If ``None`` (default) will retry 3 times, see ``Retry.DEFAULT``. Pass a\n            :class:`~urllib3.util.retry.Retry` object for fine-grained control\n            over different types of retries.\n            Pass an integer number to retry connection errors that many times,\n            but no other types of errors. Pass zero to never retry.\n    \n            If ``False``, then retries are disabled and any exception is raised\n            immediately. Also, instead of raising a MaxRetryError on redirects,\n            the redirect response will be returned.\n    \n        :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.\n    \n        :param redirect:\n            If True, automatically handle redirects (status codes 301, 302,\n            303, 307, 308). Each redirect counts as a retry. Disabling retries\n            will disable redirect, too.\n    \n        :param assert_same_host:\n            If ``True``, will make sure that the host of the pool requests is\n            consistent else will raise HostChangedError. When ``False``, you can\n            use the pool on an HTTP proxy and request foreign hosts.\n    \n        :param timeout:\n            If specified, overrides the default timeout for this one\n            request. It may be a float (in seconds) or an instance of\n            :class:`urllib3.util.Timeout`.\n    \n        :param pool_timeout:\n            If set and the pool is set to block=True, then this method will\n            block for ``pool_timeout`` seconds and raise EmptyPoolError if no\n            connection is available within the time period.\n    \n        :param bool preload_content:\n            If True, the response's body will be preloaded into memory.\n    \n        :param bool decode_content:\n            If True, will attempt to decode the body based on the\n            'content-encoding' header.\n    \n        :param release_conn:\n            If False, then the urlopen call will not release the connection\n            back into the pool once a response is received (but will release if\n            you read the entire contents of the response such as when\n            `preload_content=True`). This is useful if you're not preloading\n            the response's content immediately. You will need to call\n            ``r.release_conn()`` on the response ``r`` to return the connection\n            back into the pool. If None, it takes the value of ``preload_content``\n            which defaults to ``True``.\n    \n        :param bool chunked:\n            If True, urllib3 will send the body using chunked transfer\n            encoding. Otherwise, urllib3 will send the body using the standard\n            content-length form. Defaults to False.\n    \n        :param int body_pos:\n            Position to seek to in file-like body in the event of a retry or\n            redirect. Typically this won't need to be set because urllib3 will\n            auto-populate the value when needed.\n        \"\"\"\n        parsed_url = parse_url(url)\n        destination_scheme = parsed_url.scheme\n    \n        if headers is None:\n            headers = self.headers\n    \n        if not isinstance(retries, Retry):\n            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)\n    \n        if release_conn is None:\n            release_conn = preload_content\n    \n        # Check host\n        if assert_same_host and not self.is_same_host(url):\n            raise HostChangedError(self, url, retries)\n    \n        # Ensure that the URL we're connecting to is properly encoded\n        if url.startswith(\"/\"):\n            url = to_str(_encode_target(url))\n        else:\n            url = to_str(parsed_url.url)\n    \n        conn = None\n    \n        # Track whether `conn` needs to be released before\n        # returning/raising/recursing. Update this variable if necessary, and\n        # leave `release_conn` constant throughout the function. That way, if\n        # the function recurses, the original value of `release_conn` will be\n        # passed down into the recursive call, and its value will be respected.\n        #\n        # See issue #651 [1] for details.\n        #\n        # [1] <https://github.com/urllib3/urllib3/issues/651>\n        release_this_conn = release_conn\n    \n        http_tunnel_required = connection_requires_http_tunnel(\n            self.proxy, self.proxy_config, destination_scheme\n        )\n    \n        # Merge the proxy headers. Only done when not using HTTP CONNECT. We\n        # have to copy the headers dict so we can safely change it without those\n        # changes being reflected in anyone else's copy.\n        if not http_tunnel_required:\n            headers = headers.copy()  # type: ignore[attr-defined]\n            headers.update(self.proxy_headers)  # type: ignore[union-attr]\n    \n        # Must keep the exception bound to a separate variable or else Python 3\n        # complains about UnboundLocalError.\n        err = None\n    \n        # Keep track of whether we cleanly exited the except block. This\n        # ensures we do proper cleanup in finally.\n        clean_exit = False\n    \n        # Rewind body position, if needed. Record current position\n        # for future rewinds in the event of a redirect/retry.\n        body_pos = set_file_position(body, body_pos)\n    \n        try:\n            # Request a connection from the queue.\n            timeout_obj = self._get_timeout(timeout)\n            conn = self._get_conn(timeout=pool_timeout)\n    \n            conn.timeout = timeout_obj.connect_timeout  # type: ignore[assignment]\n    \n            # Is this a closed/new connection that requires CONNECT tunnelling?\n            if self.proxy is not None and http_tunnel_required and conn.is_closed:\n                try:\n>                   self._prepare_proxy(conn)\n\n..\\Community\\lib\\site-packages\\urllib3\\connectionpool.py:775: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n..\\Community\\lib\\site-packages\\urllib3\\connectionpool.py:1044: in _prepare_proxy\n    conn.connect()\n..\\Community\\lib\\site-packages\\urllib3\\connection.py:702: in connect\n    self.sock = sock = self._connect_tls_proxy(self.host, sock)\n..\\Community\\lib\\site-packages\\urllib3\\connection.py:802: in _connect_tls_proxy\n    sock_and_verified = _ssl_wrap_socket_and_match_hostname(\n..\\Community\\lib\\site-packages\\urllib3\\connection.py:909: in _ssl_wrap_socket_and_match_hostname\n    ssl_sock = ssl_wrap_socket(\n..\\Community\\lib\\site-packages\\urllib3\\util\\ssl_.py:469: in ssl_wrap_socket\n    ssl_sock = _ssl_wrap_socket_impl(sock, context, tls_in_tls, server_hostname)\n..\\Community\\lib\\site-packages\\urllib3\\util\\ssl_.py:513: in _ssl_wrap_socket_impl\n    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)\nD:\\python_tools\\python\\lib\\ssl.py:500: in wrap_socket\n    return self.sslsocket_class._create(\nD:\\python_tools\\python\\lib\\ssl.py:1040: in _create\n    self.do_handshake()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <ssl.SSLSocket [closed] fd=-1, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0>\nblock = False\n\n    @_sslcopydoc\n    def do_handshake(self, block=False):\n        self._check_connected()\n        timeout = self.gettimeout()\n        try:\n            if timeout == 0.0 and block:\n                self.settimeout(None)\n>           self._sslobj.do_handshake()\nE           FileNotFoundError: [Errno 2] No such file or directory\n\nD:\\python_tools\\python\\lib\\ssl.py:1309: FileNotFoundError\n\nThe above exception was the direct cause of the following exception:\nTraceback (most recent call last):\n  File \"D:\\pycharm_test\\Community\\lib\\site-packages\\urllib3\\connectionpool.py\", line 775, in urlopen\n    self._prepare_proxy(conn)\n  File \"D:\\pycharm_test\\Community\\lib\\site-packages\\urllib3\\connectionpool.py\", line 1044, in _prepare_proxy\n    conn.connect()\n  File \"D:\\pycharm_test\\Community\\lib\\site-packages\\urllib3\\connection.py\", line 702, in connect\n    self.sock = sock = self._connect_tls_proxy(self.host, sock)\n  File \"D:\\pycharm_test\\Community\\lib\\site-packages\\urllib3\\connection.py\", line 802, in _connect_tls_proxy\n    sock_and_verified = _ssl_wrap_socket_and_match_hostname(\n  File \"D:\\pycharm_test\\Community\\lib\\site-packages\\urllib3\\connection.py\", line 909, in _ssl_wrap_socket_and_match_hostname\n    ssl_sock = ssl_wrap_socket(\n  File \"D:\\pycharm_test\\Community\\lib\\site-packages\\urllib3\\util\\ssl_.py\", line 469, in ssl_wrap_socket\n    ssl_sock = _ssl_wrap_socket_impl(sock, context, tls_in_tls, server_hostname)\n  File \"D:\\pycharm_test\\Community\\lib\\site-packages\\urllib3\\util\\ssl_.py\", line 513, in _ssl_wrap_socket_impl\n    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)\n  File \"D:\\python_tools\\python\\lib\\ssl.py\", line 500, in wrap_socket\n    return self.sslsocket_class._create(\n  File \"D:\\python_tools\\python\\lib\\ssl.py\", line 1040, in _create\n    self.do_handshake()\n  File \"D:\\python_tools\\python\\lib\\ssl.py\", line 1309, in do_handshake\n    self._sslobj.do_handshake()\nFileNotFoundError: [Errno 2] No such file or directory\n\nThe above exception was the direct cause of the following exception:\n\nurllib3.exceptions.ProxyError: ('Unable to connect to proxy', FileNotFoundError(2, 'No such file or directory'))\n\nThe above exception was the direct cause of the following exception:\n\nself = <requests.adapters.HTTPAdapter object at 0x000001D22C6C4E80>\nrequest = <PreparedRequest [POST]>, stream = False\ntimeout = Timeout(connect=None, read=None, total=None), verify = True\ncert = None\nproxies = OrderedDict([('http', 'http://127.0.0.1:10809'), ('https', 'https://127.0.0.1:10809'), ('ftp', 'ftp://127.0.0.1:10809')])\n\n    def send(\n        self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None\n    ):\n        \"\"\"Sends PreparedRequest object. Returns Response object.\n    \n        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\n        :param stream: (optional) Whether to stream the request content.\n        :param timeout: (optional) How long to wait for the server to send\n            data before giving up, as a float, or a :ref:`(connect timeout,\n            read timeout) <timeouts>` tuple.\n        :type timeout: float or tuple or urllib3 Timeout object\n        :param verify: (optional) Either a boolean, in which case it controls whether\n            we verify the server's TLS certificate, or a string, in which case it\n            must be a path to a CA bundle to use\n        :param cert: (optional) Any user-provided SSL certificate to be trusted.\n        :param proxies: (optional) The proxies dictionary to apply to the request.\n        :rtype: requests.Response\n        \"\"\"\n    \n        try:\n            conn = self.get_connection_with_tls_context(\n                request, verify, proxies=proxies, cert=cert\n            )\n        except LocationValueError as e:\n            raise InvalidURL(e, request=request)\n    \n        self.cert_verify(conn, request.url, verify, cert)\n        url = self.request_url(request, proxies)\n        self.add_headers(\n            request,\n            stream=stream,\n            timeout=timeout,\n            verify=verify,\n            cert=cert,\n            proxies=proxies,\n        )\n    \n        chunked = not (request.body is None or \"Content-Length\" in request.headers)\n    \n        if isinstance(timeout, tuple):\n            try:\n                connect, read = timeout\n                timeout = TimeoutSauce(connect=connect, read=read)\n            except ValueError:\n                raise ValueError(\n                    f\"Invalid timeout {timeout}. Pass a (connect, read) timeout tuple, \"\n                    f\"or a single float to set both timeouts to the same value.\"\n                )\n        elif isinstance(timeout, TimeoutSauce):\n            pass\n        else:\n            timeout = TimeoutSauce(connect=timeout, read=timeout)\n    \n        try:\n>           resp = conn.urlopen(\n                method=request.method,\n                url=url,\n                body=request.body,\n                headers=request.headers,\n                redirect=False,\n                assert_same_host=False,\n                preload_content=False,\n                decode_content=False,\n                retries=self.max_retries,\n                timeout=timeout,\n                chunked=chunked,\n            )\n\n..\\Community\\lib\\site-packages\\requests\\adapters.py:667: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n..\\Community\\lib\\site-packages\\urllib3\\connectionpool.py:843: in urlopen\n    retries = retries.increment(\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = Retry(total=0, connect=None, read=False, redirect=None, status=None)\nmethod = 'POST'\nurl = '/api/blockchain/account/unbindPa?traderId=1978748962360750082'\nresponse = None\nerror = ProxyError('Unable to connect to proxy', FileNotFoundError(2, 'No such file or directory'))\n_pool = <urllib3.connectionpool.HTTPSConnectionPool object at 0x000001D22C9D3850>\n_stacktrace = <traceback object at 0x000001D22E4E1040>\n\n    def increment(\n        self,\n        method: str | None = None,\n        url: str | None = None,\n        response: BaseHTTPResponse | None = None,\n        error: Exception | None = None,\n        _pool: ConnectionPool | None = None,\n        _stacktrace: TracebackType | None = None,\n    ) -> Self:\n        \"\"\"Return a new Retry object with incremented retry counters.\n    \n        :param response: A response object, or None, if the server did not\n            return a response.\n        :type response: :class:`~urllib3.response.BaseHTTPResponse`\n        :param Exception error: An error encountered during the request, or\n            None if the response was received successfully.\n    \n        :return: A new ``Retry`` object.\n        \"\"\"\n        if self.total is False and error:\n            # Disabled, indicate to re-raise the error.\n            raise reraise(type(error), error, _stacktrace)\n    \n        total = self.total\n        if total is not None:\n            total -= 1\n    \n        connect = self.connect\n        read = self.read\n        redirect = self.redirect\n        status_count = self.status\n        other = self.other\n        cause = \"unknown\"\n        status = None\n        redirect_location = None\n    \n        if error and self._is_connection_error(error):\n            # Connect retry?\n            if connect is False:\n                raise reraise(type(error), error, _stacktrace)\n            elif connect is not None:\n                connect -= 1\n    \n        elif error and self._is_read_error(error):\n            # Read retry?\n            if read is False or method is None or not self._is_method_retryable(method):\n                raise reraise(type(error), error, _stacktrace)\n            elif read is not None:\n                read -= 1\n    \n        elif error:\n            # Other retry?\n            if other is not None:\n                other -= 1\n    \n        elif response and response.get_redirect_location():\n            # Redirect retry?\n            if redirect is not None:\n                redirect -= 1\n            cause = \"too many redirects\"\n            response_redirect_location = response.get_redirect_location()\n            if response_redirect_location:\n                redirect_location = response_redirect_location\n            status = response.status\n    \n        else:\n            # Incrementing because of a server error like a 500 in\n            # status_forcelist and the given method is in the allowed_methods\n            cause = ResponseError.GENERIC_ERROR\n            if response and response.status:\n                if status_count is not None:\n                    status_count -= 1\n                cause = ResponseError.SPECIFIC_ERROR.format(status_code=response.status)\n                status = response.status\n    \n        history = self.history + (\n            RequestHistory(method, url, error, status, redirect_location),\n        )\n    \n        new_retry = self.new(\n            total=total,\n            connect=connect,\n            read=read,\n            redirect=redirect,\n            status=status_count,\n            other=other,\n            history=history,\n        )\n    \n        if new_retry.is_exhausted():\n            reason = error or ResponseError(cause)\n>           raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\nE           urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='dev.lgcopytrade.top', port=443): Max retries exceeded with url: /api/blockchain/account/unbindPa?traderId=1978748962360750082 (Caused by ProxyError('Unable to connect to proxy', FileNotFoundError(2, 'No such file or directory')))\n\n..\\Community\\lib\\site-packages\\urllib3\\util\\retry.py:519: MaxRetryError\n\nDuring handling of the above exception, another exception occurred:\n\nself = <template.test_cloudTrader.test_delete.Test_delete object at 0x000001D22C6BDFD0>\nlogged_session = <template.commons.session.EnvironmentSession object at 0x000001D22C6C44C0>\nurl = '/blockchain/account/unbindPa', json_data = None, data = None\nfiles = None, params = {'traderId': '1978748962360750082'}, sleep_seconds = 3\n\n    def send_post_request(self, logged_session, url, json_data=None, data=None, files=None,\n                          params=None,  # 新增：支持URL查询参数\n                          sleep_seconds=SLEEP_SECONDS):\n        \"\"\"发送POST请求（异常分层优化，新增params参数支持URL查询）\"\"\"\n        method = \"POST\"\n        with allure.step(f\"执行 {method} 请求\"):\n            try:\n                # 1. 附加请求详情到Allure（新增params展示）\n                self._attach_request_details(\n                    method=method,\n                    url=url,\n                    headers=logged_session.headers,\n                    params=params,  # 新增：将params传入，用于Allure展示\n                    body=json_data if json_data else data,\n                    is_json=bool(json_data),\n                )\n    \n                # 2. 发送POST请求（根据不同场景携带params）\n                if files:\n                    # 场景1：带文件上传（表单数据+URL参数）\n                    response = logged_session.post(\n                        url=url,\n                        data=data,\n                        files=files,\n                        params=params  # 新增：传递URL参数\n                    )\n                    logger.info(\n                        f\"[{self._get_current_time()}] POST请求（带文件+URL参数）: {url} \"\n                        f\"| URL参数: {params} | 表单数据: {data}\"\n                    )\n                elif json_data:\n                    # 场景2：JSON请求体（JSON数据+URL参数）\n                    response = logged_session.post(\n                        url=url,\n                        json=json_data,\n                        params=params  # 新增：传递URL参数\n                    )\n                    logger.info(\n                        f\"[{self._get_current_time()}] POST请求（JSON+URL参数）: {url} \"\n                        f\"| URL参数: {params} | JSON数据: {json_data}\"\n                    )\n                else:\n                    # 场景3：普通表单请求（表单数据+URL参数）\n>                   response = logged_session.post(\n                        url=url,\n                        data=data,\n                        params=params  # 新增：传递URL参数\n                    )\n\ncommons\\api_base.py:215: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n..\\Community\\lib\\site-packages\\requests\\sessions.py:637: in post\n    return self.request(\"POST\", url, data=data, json=json, **kwargs)\ncommons\\session.py:135: in request\n    response = super().request(method, full_url, *args, **kwargs)\n..\\Community\\lib\\site-packages\\requests\\sessions.py:589: in request\n    resp = self.send(prep, **send_kwargs)\n..\\Community\\lib\\site-packages\\requests\\sessions.py:703: in send\n    r = adapter.send(request, **kwargs)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <requests.adapters.HTTPAdapter object at 0x000001D22C6C4E80>\nrequest = <PreparedRequest [POST]>, stream = False\ntimeout = Timeout(connect=None, read=None, total=None), verify = True\ncert = None\nproxies = OrderedDict([('http', 'http://127.0.0.1:10809'), ('https', 'https://127.0.0.1:10809'), ('ftp', 'ftp://127.0.0.1:10809')])\n\n    def send(\n        self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None\n    ):\n        \"\"\"Sends PreparedRequest object. Returns Response object.\n    \n        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\n        :param stream: (optional) Whether to stream the request content.\n        :param timeout: (optional) How long to wait for the server to send\n            data before giving up, as a float, or a :ref:`(connect timeout,\n            read timeout) <timeouts>` tuple.\n        :type timeout: float or tuple or urllib3 Timeout object\n        :param verify: (optional) Either a boolean, in which case it controls whether\n            we verify the server's TLS certificate, or a string, in which case it\n            must be a path to a CA bundle to use\n        :param cert: (optional) Any user-provided SSL certificate to be trusted.\n        :param proxies: (optional) The proxies dictionary to apply to the request.\n        :rtype: requests.Response\n        \"\"\"\n    \n        try:\n            conn = self.get_connection_with_tls_context(\n                request, verify, proxies=proxies, cert=cert\n            )\n        except LocationValueError as e:\n            raise InvalidURL(e, request=request)\n    \n        self.cert_verify(conn, request.url, verify, cert)\n        url = self.request_url(request, proxies)\n        self.add_headers(\n            request,\n            stream=stream,\n            timeout=timeout,\n            verify=verify,\n            cert=cert,\n            proxies=proxies,\n        )\n    \n        chunked = not (request.body is None or \"Content-Length\" in request.headers)\n    \n        if isinstance(timeout, tuple):\n            try:\n                connect, read = timeout\n                timeout = TimeoutSauce(connect=connect, read=read)\n            except ValueError:\n                raise ValueError(\n                    f\"Invalid timeout {timeout}. Pass a (connect, read) timeout tuple, \"\n                    f\"or a single float to set both timeouts to the same value.\"\n                )\n        elif isinstance(timeout, TimeoutSauce):\n            pass\n        else:\n            timeout = TimeoutSauce(connect=timeout, read=timeout)\n    \n        try:\n            resp = conn.urlopen(\n                method=request.method,\n                url=url,\n                body=request.body,\n                headers=request.headers,\n                redirect=False,\n                assert_same_host=False,\n                preload_content=False,\n                decode_content=False,\n                retries=self.max_retries,\n                timeout=timeout,\n                chunked=chunked,\n            )\n    \n        except (ProtocolError, OSError) as err:\n            raise ConnectionError(err, request=request)\n    \n        except MaxRetryError as e:\n            if isinstance(e.reason, ConnectTimeoutError):\n                # TODO: Remove this in 3.0.0: see #2811\n                if not isinstance(e.reason, NewConnectionError):\n                    raise ConnectTimeout(e, request=request)\n    \n            if isinstance(e.reason, ResponseError):\n                raise RetryError(e, request=request)\n    \n            if isinstance(e.reason, _ProxyError):\n>               raise ProxyError(e, request=request)\nE               requests.exceptions.ProxyError: HTTPSConnectionPool(host='dev.lgcopytrade.top', port=443): Max retries exceeded with url: /api/blockchain/account/unbindPa?traderId=1978748962360750082 (Caused by ProxyError('Unable to connect to proxy', FileNotFoundError(2, 'No such file or directory')))\n\n..\\Community\\lib\\site-packages\\requests\\adapters.py:694: ProxyError\n\nThe above exception was the direct cause of the following exception:\n\nself = <template.test_cloudTrader.test_delete.Test_delete object at 0x000001D22C6BDFD0>\nvar_manager = <template.commons.variable_manager.VariableManager object at 0x000001D22C6C4BE0>\nlogged_session = <template.commons.session.EnvironmentSession object at 0x000001D22C6C44C0>\n\n>   ???\n\nD:\\pycharm_test\\template\\test_community\\test_delete.py:247: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <template.test_cloudTrader.test_delete.Test_delete object at 0x000001D22C6BDFD0>\nlogged_session = <template.commons.session.EnvironmentSession object at 0x000001D22C6C44C0>\nurl = '/blockchain/account/unbindPa', json_data = None, data = None\nfiles = None, params = {'traderId': '1978748962360750082'}, sleep_seconds = 3\n\n    def send_post_request(self, logged_session, url, json_data=None, data=None, files=None,\n                          params=None,  # 新增：支持URL查询参数\n                          sleep_seconds=SLEEP_SECONDS):\n        \"\"\"发送POST请求（异常分层优化，新增params参数支持URL查询）\"\"\"\n        method = \"POST\"\n        with allure.step(f\"执行 {method} 请求\"):\n            try:\n                # 1. 附加请求详情到Allure（新增params展示）\n                self._attach_request_details(\n                    method=method,\n                    url=url,\n                    headers=logged_session.headers,\n                    params=params,  # 新增：将params传入，用于Allure展示\n                    body=json_data if json_data else data,\n                    is_json=bool(json_data),\n                )\n    \n                # 2. 发送POST请求（根据不同场景携带params）\n                if files:\n                    # 场景1：带文件上传（表单数据+URL参数）\n                    response = logged_session.post(\n                        url=url,\n                        data=data,\n                        files=files,\n                        params=params  # 新增：传递URL参数\n                    )\n                    logger.info(\n                        f\"[{self._get_current_time()}] POST请求（带文件+URL参数）: {url} \"\n                        f\"| URL参数: {params} | 表单数据: {data}\"\n                    )\n                elif json_data:\n                    # 场景2：JSON请求体（JSON数据+URL参数）\n                    response = logged_session.post(\n                        url=url,\n                        json=json_data,\n                        params=params  # 新增：传递URL参数\n                    )\n                    logger.info(\n                        f\"[{self._get_current_time()}] POST请求（JSON+URL参数）: {url} \"\n                        f\"| URL参数: {params} | JSON数据: {json_data}\"\n                    )\n                else:\n                    # 场景3：普通表单请求（表单数据+URL参数）\n                    response = logged_session.post(\n                        url=url,\n                        data=data,\n                        params=params  # 新增：传递URL参数\n                    )\n                    logger.info(\n                        f\"[{self._get_current_time()}] POST请求（表单+URL参数）: {url} \"\n                        f\"| URL参数: {params} | 表单数据: {data}\"\n                    )\n    \n                # 3. 附加响应详情（原有逻辑不变）\n                self._attach_response_details(response)\n    \n                # 4. 请求后等待（原有逻辑不变）\n                if sleep_seconds > 0:\n                    logger.info(f\"[{self._get_current_time()}] 请求后等待 {sleep_seconds} 秒\")\n                    time.sleep(sleep_seconds)\n    \n                return response\n    \n            # 5. 异常捕获与处理（新增params到异常详情）\n            except (SSLError, ConnectionError, Timeout, RequestException) as e:\n                with allure.step(f\"{method} 请求异常\"):\n                    self._attach_request_details(\n                        method=method,\n                        url=url,\n                        headers=logged_session.headers,\n                        params=params,  # 新增：异常时也展示URL参数\n                        body=json_data if json_data else data,\n                        is_json=bool(json_data),\n                    )\n                    error_detail = (\n                        f\"请求异常: {str(e)}\\n\"\n                        f\"URL: {url}\\n\"\n                        f\"URL参数: {params}\\n\"  # 新增：异常详情中显示URL参数\n                        f\"请求头: {logged_session.headers}\\n\"\n                        f\"请求体: {json_data if json_data else data}\"\n                    )\n                    allure.attach(error_detail, \"请求异常详情\", allure.attachment_type.TEXT)\n                logger.error(\n                    f\"[{self._get_current_time()}] {method} 请求异常: {str(e)} \"\n                    f\"| URL: {url} | URL参数: {params}\",  # 新增：日志中打印URL参数\n                    exc_info=True\n                )\n>               raise ConnectionError(f\"Failed: {method} 请求异常（{str(e)[:1000]}）\") from e\nE               requests.exceptions.ConnectionError: Failed: POST 请求异常（HTTPSConnectionPool(host='dev.lgcopytrade.top', port=443): Max retries exceeded with url: /api/blockchain/account/unbindPa?traderId=1978748962360750082 (Caused by ProxyError('Unable to connect to proxy', FileNotFoundError(2, 'No such file or directory')))）\n\ncommons\\api_base.py:259: ConnectionError",
    "steps" : [ {
      "name" : "执行 POST 请求",
      "time" : {
        "start" : 1760606119790,
        "stop" : 1760606119808,
        "duration" : 18
      },
      "status" : "broken",
      "statusMessage" : "requests.exceptions.ConnectionError: Failed: POST 请求异常（HTTPSConnectionPool(host='dev.lgcopytrade.top', port=443): Max retries exceeded with url: /api/blockchain/account/unbindPa?traderId=1978748962360750082 (Caused by ProxyError('Unable to connect to proxy', FileNotFoundError(2, 'No such file or directory')))）\n",
      "statusTrace" : "  File \"D:\\pycharm_test\\template\\commons\\api_base.py\", line 259, in send_post_request\n    raise ConnectionError(f\"Failed: {method} 请求异常（{str(e)[:1000]}）\") from e\n",
      "steps" : [ {
        "name" : "请求详情",
        "time" : {
          "start" : 1760606119790,
          "stop" : 1760606119791,
          "duration" : 1
        },
        "status" : "passed",
        "steps" : [ ],
        "attachments" : [ {
          "uid" : "ad90ef09e85764c9",
          "name" : "请求完整URL（含参数）",
          "source" : "ad90ef09e85764c9.txt",
          "type" : "text/plain",
          "size" : 57
        }, {
          "uid" : "f13218f0ac2a79ed",
          "name" : "URL查询参数",
          "source" : "f13218f0ac2a79ed.json",
          "type" : "application/json",
          "size" : 39
        }, {
          "uid" : "4f4e5ead7eebdc40",
          "name" : "请求头",
          "source" : "4f4e5ead7eebdc40.json",
          "type" : "application/json",
          "size" : 429
        } ],
        "parameters" : [ ],
        "hasContent" : true,
        "stepsCount" : 0,
        "attachmentsCount" : 3,
        "shouldDisplayMessage" : false
      }, {
        "name" : "POST 请求异常",
        "time" : {
          "start" : 1760606119806,
          "stop" : 1760606119807,
          "duration" : 1
        },
        "status" : "passed",
        "steps" : [ {
          "name" : "请求详情",
          "time" : {
            "start" : 1760606119806,
            "stop" : 1760606119807,
            "duration" : 1
          },
          "status" : "passed",
          "steps" : [ ],
          "attachments" : [ {
            "uid" : "2acd1f957374d01e",
            "name" : "请求完整URL（含参数）",
            "source" : "2acd1f957374d01e.txt",
            "type" : "text/plain",
            "size" : 57
          }, {
            "uid" : "7434b78ca1aa8366",
            "name" : "URL查询参数",
            "source" : "7434b78ca1aa8366.json",
            "type" : "application/json",
            "size" : 39
          }, {
            "uid" : "86b8596acfefc8a5",
            "name" : "请求头",
            "source" : "86b8596acfefc8a5.json",
            "type" : "application/json",
            "size" : 429
          } ],
          "parameters" : [ ],
          "hasContent" : true,
          "stepsCount" : 0,
          "attachmentsCount" : 3,
          "shouldDisplayMessage" : false
        } ],
        "attachments" : [ {
          "uid" : "569bb885eaa5947d",
          "name" : "请求异常详情",
          "source" : "569bb885eaa5947d.txt",
          "type" : "text/plain",
          "size" : 787
        } ],
        "parameters" : [ ],
        "hasContent" : true,
        "stepsCount" : 1,
        "attachmentsCount" : 4,
        "shouldDisplayMessage" : false
      } ],
      "attachments" : [ ],
      "parameters" : [ ],
      "hasContent" : true,
      "stepsCount" : 3,
      "attachmentsCount" : 7,
      "shouldDisplayMessage" : true
    } ],
    "attachments" : [ {
      "uid" : "7b1271c6a1b95381",
      "name" : "log",
      "source" : "7b1271c6a1b95381.txt",
      "type" : "text/plain",
      "size" : 2878
    } ],
    "parameters" : [ ],
    "hasContent" : true,
    "stepsCount" : 4,
    "attachmentsCount" : 8,
    "shouldDisplayMessage" : true
  },
  "afterStages" : [ ],
  "labels" : [ {
    "name" : "feature",
    "value" : "账号管理-删除账号"
  }, {
    "name" : "parentSuite",
    "value" : "test_cloudTrader"
  }, {
    "name" : "suite",
    "value" : "test_delete"
  }, {
    "name" : "subSuite",
    "value" : "Test_delete"
  }, {
    "name" : "host",
    "value" : "DESKTOP-4S9CU1E"
  }, {
    "name" : "thread",
    "value" : "67168-MainThread"
  }, {
    "name" : "framework",
    "value" : "pytest"
  }, {
    "name" : "language",
    "value" : "cpython3"
  }, {
    "name" : "package",
    "value" : "test_cloudTrader.test_delete"
  }, {
    "name" : "resultFormat",
    "value" : "allure2"
  } ],
  "parameters" : [ ],
  "links" : [ ],
  "hidden" : true,
  "retry" : true,
  "extra" : {
    "categories" : [ ],
    "tags" : [ ]
  },
  "source" : "75a809ce7d1b4e99.json",
  "parameterValues" : [ ]
}